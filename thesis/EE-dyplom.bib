
@article{sharma_application_2021,
	title = {The {Application} of {Image} {Processing} in {Liver} {Cancer} {Detection}},
	volume = {12},
	issn = {21565570, 2158107X},
	url = {http://thesai.org/Publications/ViewPaper?Volume=12&Issue=10&Code=IJACSA&SerialNo=50},
	doi = {10.14569/IJACSA.2021.0121050},
	abstract = {Hepatic cancer is caused by the uncontrolled growth of liver cells, an HCC is the most common form of malignant liver cancer, accounting for 75 percent of cases. This tumor is difficult to diagnose, and it is often discovered at an advanced stage, posing a life-threatening danger. As a result, early diagnosis of liver cancer increases life expectancy. So, using a digital image processing method, we suggest an automated computer-aided diagnosis of liver tumors from MRI images. Magnetic Resonance Imaging (MRI) images are used to identify liver tumors in this case. The image goes through image preprocessing, image segmentation, and feature extraction, all of which are done within the layers of an Artificial Neural Network, making it an automated operation. To make the edge continuous, this operation combines two processes: edge and manual labeling. On the basis of statistical characteristics, tumors are often divided into four categories: cyst, adenoma, hemangioma, and malignant liver tumor. The aim of this proposed technique is to automatically highlight and categorize tumor regions in Magnetic Resonance Imaging images without the need for a medical practitioner.},
	language = {en},
	number = {10},
	urldate = {2024-02-28},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {Sharma, Meenu and Parveen, Rafat},
	year = {2021},
	file = {The_Application_of_Image_Processing_in_L.pdf:/Users/jasiekjaniszewski/Desktop/magisterka/papers/The_Application_of_Image_Processing_in_L.pdf:application/pdf},
}

@article{dutta_detection_nodate,
	title = {Detection of {Liver} {Cancer} using {Image} {Processing} {Techniques}},
	abstract = {Image processing is a processing technique with the help of mathematical operations. It uses any of the form of signal processing. Here the input is an image or video and the output is also an image or a set of image. This technique is also used in medical applications for various detection and treatment. In this paper, it has been used to detect cancer cell of the liver. Here ostu’s method is used for enhancing the MRI image and watershed method is used to segment the cancer cell from the image.},
	language = {en},
	author = {Dutta, Atrayee and Dubey, Aditya},
	file = {Dutta and Dubey - Detection of Liver Cancer using Image Processing T.pdf:/Users/jasiekjaniszewski/Zotero/storage/3WEIDXPT/Dutta and Dubey - Detection of Liver Cancer using Image Processing T.pdf:application/pdf},
}

@inproceedings{anisha_pragmatic_2015,
	address = {Guntur, India},
	title = {A pragmatic approach for detecting liver cancer using image processing and data mining techniques},
	isbn = {978-1-4799-6109-2},
	url = {https://ieeexplore.ieee.org/document/7058282},
	doi = {10.1109/SPACES.2015.7058282},
	abstract = {Cancer diagnosis and treatment has a great significance due to the prevalent episodes of the diseases, high death rate and reappearance after treatment.. On the world scale, cancer stands in the fifth position which causes death. Among the various cancers, liver cancer stands in the third position. Liver cancer is generally diagnosed by three different test like blood test, image test and biopsy. To make the task of detecting the liver cancer simpler, less time consuming, an effective and efficient approach is adopted for the same. In this research a computer aided diagnostic system for detecting liver cancer is put forward. The proposed detection methodology makes use of MRI, CT and USG scan imagery. Kmeans clustering technique is adopted so as to segment the images in order to capture the region of interest. Later, Haar wavelet transform is considered to compute the threshold values for the region of interest. The experiment put forth gave an average accuracy of 82\% besides reducing the time complexity and computational complexity of the test.},
	language = {en},
	urldate = {2024-02-28},
	booktitle = {2015 {International} {Conference} on {Signal} {Processing} and {Communication} {Engineering} {Systems}},
	publisher = {IEEE},
	author = {Anisha, P R and Reddy, C Kishor Kumar and Prasad, L V Narasimha},
	month = jan,
	year = {2015},
	pages = {352--357},
	file = {Anisha et al. - 2015 - A pragmatic approach for detecting liver cancer us.pdf:/Users/jasiekjaniszewski/Zotero/storage/9UET35U3/Anisha et al. - 2015 - A pragmatic approach for detecting liver cancer us.pdf:application/pdf},
}

@article{li_application_2020,
	title = {Application of {Image} {Fusion} in {Diagnosis} and {Treatment} of {Liver} {Cancer}},
	volume = {10},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/10/3/1171},
	doi = {10.3390/app10031171},
	abstract = {With the accelerated development of medical imaging equipment and techniques, image fusion technology has been eﬀectively applied for diagnosis, biopsy and radiofrequency ablation, especially for liver tumor. Tumor treatment relying on a single medical imaging modality might face challenges, due to the deep positioning of the lesions, operation history and the speciﬁc background conditions of the liver disease. Image fusion technology has been employed to address these challenges. Using the image fusion technology, one could obtain real-time anatomical imaging superimposed by functional images showing the same plane to facilitate the diagnosis and treatments of liver tumors. This paper presents a review of the key principles of image fusion technology, its application in tumor treatments, particularly in liver tumors, and concludes with a discussion of the limitations and prospects of the image fusion technology.},
	language = {en},
	number = {3},
	urldate = {2024-02-28},
	journal = {Applied Sciences},
	author = {Li, Chengxi and Zhu, Andrew},
	month = feb,
	year = {2020},
	pages = {1171},
	file = {Li and Zhu - 2020 - Application of Image Fusion in Diagnosis and Treat.pdf:/Users/jasiekjaniszewski/Zotero/storage/W9NL8UHL/Li and Zhu - 2020 - Application of Image Fusion in Diagnosis and Treat.pdf:application/pdf},
}

@article{ali_diagnosis_2015,
	title = {Diagnosis of {Liver} {Tumor} from {CT} {Images} using {Digital} {Image} {Processing}},
	volume = {6},
	abstract = {The detection and diagnose of liver tumors from CT images by using digital image processing, is a modern technique depends on using computer in addition to textural analysis to obtain an accurate liver diagnosis, despite the method's difficulty that came from liver's position in the abdomen among the other organs. This method will make the surgeon able to detect the tumor and then easing treatment also it helps physicians and radiologists to identify the affected parts of the liver in order to protect the normal parts as much as possible from exposure to radiation. This study describes a new 2D liver segmentation method for purpose of transplantation surgery as a treatment for liver tumors. Liver segmentation is not only the key process for volume computation but also fundamental for further processing to get more anatomy information for individual patient. Due to the low contrast, blurred edges, large variability in shape and complex context with clutter features surrounding the liver that characterize the CT liver images. In this paper, the CT images are taken, and then the segmentation processes are applied to the liver image which will find, extract the CT liver boundary and further classify liver diseases.},
	language = {en},
	number = {1},
	author = {Ali, Dr Alyaa H and Hadi, Entethar M},
	year = {2015},
	file = {Ali and Hadi - 2015 - Diagnosis of Liver Tumor from CT Images using Digi.pdf:/Users/jasiekjaniszewski/Zotero/storage/A9YCB7NN/Ali and Hadi - 2015 - Diagnosis of Liver Tumor from CT Images using Digi.pdf:application/pdf},
}

@inproceedings{ali_intelligent_2014,
	address = {Orlando, FL, USA},
	title = {Intelligent image processing techniques for cancer progression detection, recognition and prediction in the human liver},
	isbn = {978-1-4799-4527-6},
	url = {http://ieeexplore.ieee.org/document/7007830/},
	doi = {10.1109/CICARE.2014.7007830},
	abstract = {Clinical Decision Support (CDS) aids in early diagnosis of liver cancer, a potentially fatal disease prevalent in both developed and developing countries. Our research aims to develop a robust and intelligent clinical decision support framework for disease management of cancer based on legacy Ultrasound (US) image data collected during various stages of liver cancer. The proposed intelligent CDS framework will automate real-time image enhancement, segmentation, disease classification and progression in order to enable efficient diagnosis of cancer patients at early stages. The CDS framework is inspired by the human interpretation of US images from the image acquisition stage to cancer progression prediction. Specifically, the proposed framework is composed of a number of stages where images are first acquired from an imaging source and pre-processed before running through an image enhancement algorithm. The detection of cancer and its segmentation is considered as the second stage in which different image segmentation techniques are utilized to partition and extract objects from the enhanced image. The third stage involves disease classification of segmented objects, in which the meanings of an investigated object are matched with the disease dictionary defined by physicians and radiologists. In the final stage; cancer progression, an array of US images is used to evaluate and predict the future stages of the disease. For experiment purposes, we applied the framework and classifiers to liver cancer dataset for 200 patients. Class distributions are 120 benign and 80 malignant in this dataset.},
	language = {en},
	urldate = {2024-02-28},
	booktitle = {2014 {IEEE} {Symposium} on {Computational} {Intelligence} in {Healthcare} and e-health ({CICARE})},
	publisher = {IEEE},
	author = {Ali, L. and Hussain, A. and Li, J. and Shah, A. and Sudhakr, U. and Mahmud, Mufti and Zakir, U. and Yan, X. and Luo, B. and Rajak, M.},
	month = dec,
	year = {2014},
	pages = {25--31},
	file = {Ali et al. - 2014 - Intelligent image processing techniques for cancer.pdf:/Users/jasiekjaniszewski/Zotero/storage/MZ7MNYWQ/Ali et al. - 2014 - Intelligent image processing techniques for cancer.pdf:application/pdf;S000511792110012X.pdf:/Users/jasiekjaniszewski/Zotero/storage/WQ7NZPUC/S000511792110012X.pdf:application/pdf},
}

@article{ramon_iglesias_gamarra_image_2020,
	title = {Image {Processing} {Applied} to {Medical} {Science} for the {Study} of {Liver} {Cancer} {Using} {Segmentation} in {Magnetic} {Resonance} {Imaging}},
	volume = {5},
	issn = {2575-1700},
	url = {http://www.sciencepublishinggroup.com/journal/paperinfo?journalid=517&doi=10.11648/j.ijics.20200501.12},
	doi = {10.11648/j.ijics.20200501.12},
	abstract = {The objective to develop some algorithms with new techniques of image processing for the automatic segmentation of the liver using magnetic resonance images. The methodology is based in a descriptive description was proposed that allows to combine the information of multiple channels using statistical models that have as a central point the multivariate and multisequence gaussian distribution. In this way, we will approach the spatial distribution having as a central point the intensity values in the different sequences and, therefore, we will be able to capture the variability of the data in each sequence at that moment. The results are based on the segmentation references and the proposed evaluation metrics to be able to validate the development different methods for segmentation were applied as inputs and what was obtained as a result of the segmentation originated a group of images that correspond to each of the cuts that have maximum resolution in the obtained sequences. All the images obtained here including the segmentation referred to, must be binary and their pixels must be marked with 1 (liver) or 0 (without liver). In conclusions the segmentation method that we propose here will consist of an active contour modeling in 2D and 3D and that will be developed in images that will be produced based on a new developed descriptor, having as an important point to minimize the image with an Approximation that is dual to the variational problem which should give us good results in the segmentation process.},
	language = {en},
	number = {1},
	urldate = {2024-02-28},
	journal = {International Journal of Information and Communication Sciences},
	author = {Ramon Iglesias Gamarra, Jose and Luz Tapias Diaz, Omaira},
	year = {2020},
	pages = {8},
	file = {Ramon Iglesias Gamarra and Luz Tapias Diaz - 2020 - Image Processing Applied to Medical Science for th.pdf:/Users/jasiekjaniszewski/Zotero/storage/EMIF5E97/Ramon Iglesias Gamarra and Luz Tapias Diaz - 2020 - Image Processing Applied to Medical Science for th.pdf:application/pdf},
}

@article{mahalaxmi_liver_2021,
	title = {Liver {Cancer} {Detection} {Using} {Various} {Image} {Segmentation} {Approaches}: {A} {Review}},
	volume = {13},
	abstract = {Liver cancer is the main source of death in the globe. Manual cancer tissue diagnosis is monotonous and troublesome. Hence, the paper fosters a high-exactness automatic diagnosis strategy for liver cancer growth. The image processing approach can utilize Computer Aided Diagnosis (CAD) for the arrangement of liver malignant growth to help the specialist. The CAD system is used to give a robotized approach to deal with successful arrangement of liver malignancy using feasible arrangements. Early affirmation and finding of liver growth are crucial for the space of liver cancers. Medical image processing is utilized to isolate tumors in a non-prominent way. Different strategies for recognizing liver tumors dependent upon abnormal lesion size and shape have been made. In like manner, automatic procedures for dividing the liver and liver tumors are pursued in clinical practice. This paper examines out a combination of liver malignant growth determination algorithms and philosophies.},
	language = {en},
	number = {3},
	author = {Mahalaxmi, Golla and Tirupal, T and Shanawaz, Syed},
	year = {2021},
	file = {Mahalaxmi et al. - 2021 - Liver Cancer Detection Using Various Image Segment.pdf:/Users/jasiekjaniszewski/Zotero/storage/TNA6JNNU/Mahalaxmi et al. - 2021 - Liver Cancer Detection Using Various Image Segment.pdf:application/pdf},
}

@article{ulagamuthalvi_automatic_2012,
	title = {Automatic {Identification} of {Ultrasound} {Liver} {Cancer} {Tumor} {Using} {Support} {Vector} {Machine}},
	abstract = {Ultrasound liver tumor image are naturally have more spackle noise. Automatic identification of ultrasound liver tumor image is a challenging task. In this proposed system, weapproach fully automatic machine learning system for indentifying the liver cancer tumor from ultrasound images. First, we segment the liver image by calculating the textural features from co-occurrence matrix and run length method. This is the best method for segmentation of ultrasound liver cancer tumor images because it is not affected speckle noise and also preserves spatial information. For classification Support Vector machine are a general algorithm based on the risk bounds of statistical learning theory. They have found numerous applications, such as in optical character recognition, object detection,face verification, text categorization and so on. The textural features for different features methods are given as input to the SVM individually. Performance analysis train and test datasets carried out separately using SVM Model. Whenever an ultrasonic liver cancer tumor image is given to the SVM classifier system, the features are calculated, classified, as normal, benign and malignant liver cancer tumor. We hope the result will be helpful to the physician to identify the liver cancer in non invasive method.},
	language = {en},
	author = {Ulagamuthalvi, V and Sridharan, D},
	year = {2012},
	file = {Ulagamuthalvi and Sridharan - 2012 - Automatic Identification of Ultrasound Liver Cance.pdf:/Users/jasiekjaniszewski/Zotero/storage/HDP2UUZ3/Ulagamuthalvi and Sridharan - 2012 - Automatic Identification of Ultrasound Liver Cance.pdf:application/pdf},
}

@article{sung_global_2021,
	title = {Global {Cancer} {Statistics} 2020: {GLOBOCAN} {Estimates} of {Incidence} and {Mortality} {Worldwide} for 36 {Cancers} in 185 {Countries}},
	volume = {71},
	issn = {0007-9235, 1542-4863},
	shorttitle = {Global {Cancer} {Statistics} 2020},
	url = {https://acsjournals.onlinelibrary.wiley.com/doi/10.3322/caac.21660},
	doi = {10.3322/caac.21660},
	abstract = {This article provides an update on the global cancer burden using the GLOBOCAN 2020 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer. Worldwide, an estimated 19.3 million new cancer cases (18.1 million excluding nonmelanoma skin cancer) and almost 10.0 million cancer deaths (9.9 million excluding nonmelanoma skin cancer) occurred in 2020. Female breast cancer has surpassed lung cancer as the most commonly diagnosed cancer, with an estimated 2.3 million new cases (11.7\%), followed by lung (11.4\%), colorectal (10.0 \%), prostate (7.3\%), and stomach (5.6\%) cancers. Lung cancer remained the leading cause of cancer death, with an estimated 1.8 million deaths (18\%), followed by colorectal (9.4\%), liver (8.3\%), stomach (7.7\%), and female breast (6.9\%) cancers. Overall incidence was from 2-fold to 3-fold higher in transitioned versus transitioning countries for both sexes, whereas mortality varied {\textless}2-fold for men and little for women. Death rates for female breast and cervical cancers, however, were considerably higher in transitioning versus transitioned countries (15.0 vs 12.8 per 100,000 and 12.4 vs 5.2 per 100,000, respectively). The global cancer burden is expected to be 28.4 million cases in 2040, a 47\% rise from 2020, with a larger increase in transitioning (64\% to 95\%) versus transitioned (32\% to 56\%) countries due to demographic changes, although this may be further exacerbated by increasing risk factors associated with globalization and a growing economy. Efforts to build a sustainable infrastructure for the dissemination of cancer prevention measures and provision of cancer care in transitioning countries is critical for global cancer control. CA Cancer J Clin 2021;71:209-249. © 2021 American Cancer Society.},
	language = {en},
	number = {3},
	urldate = {2024-03-20},
	journal = {CA: A Cancer Journal for Clinicians},
	author = {Sung, Hyuna and Ferlay, Jacques and Siegel, Rebecca L. and Laversanne, Mathieu and Soerjomataram, Isabelle and Jemal, Ahmedin and Bray, Freddie},
	month = may,
	year = {2021},
	pages = {209--249},
	file = {Sung et al. - 2021 - Global Cancer Statistics 2020 GLOBOCAN Estimates .pdf:/Users/jasiekjaniszewski/Zotero/storage/H7BILVIG/Sung et al. - 2021 - Global Cancer Statistics 2020 GLOBOCAN Estimates .pdf:application/pdf},
}

@inproceedings{thein_image_2018,
	address = {Surabaya, Indonesia},
	title = {An image preprocessing method for kidney stone segmentation in {CT} scan images},
	isbn = {978-1-5386-7509-0},
	url = {https://ieeexplore.ieee.org/document/8710933/},
	doi = {10.1109/CENIM.2018.8710933},
	abstract = {In 3D medical imaging, anatomical and other structuressuchaskidneystonesareoftenidentiﬁedandextractedwith the aid of diagnosis and assessment of disease. Automatic kidney stone segmentation from abdominal CT images is challenging on the aspects of segmentation accuracy due to its variety of size, shape and location. The performance of 3D organ segmentation algorithm is also degraded by the image complexity containing multiple organs and because of their huge size. The current need is a preprocessing algorithm to assist the segmentation process. The objective of the present study was to develop reader independent preprocessing algorithm for kidney stone detection and segmentation in CT images. Three thresholding algorithms based on intensity, size and location are applied for unwanted regions removing such as soft-organ removing, bony skeleton removing and bed-mat removing. The digitized transverse abdomen CT scans images from 30 patients with kidney stone cases were included in statistical analysis and validation. As validation data for analysis, the estimation of coordinatepointsinstoneregionwasmeasuredindependentlyby expert radiology. Experimental results prove that the proposed preprocessing algorithm has 95.24\% sensitivity as the evaluation parameter. So, it can reduce the noise and unwanted regions in each procedure with good detection.},
	language = {en},
	urldate = {2024-03-22},
	booktitle = {2018 {International} {Conference} on {Computer} {Engineering}, {Network} and {Intelligent} {Multimedia} ({CENIM})},
	publisher = {IEEE},
	author = {Thein, Nilar and Nugroho, Hanung Adi and Adji, Teguh Bharata and Hamamoto, Kazuhiko},
	month = nov,
	year = {2018},
	pages = {147--150},
	file = {Thein et al. - 2018 - An image preprocessing method for kidney stone seg.pdf:/Users/jasiekjaniszewski/Zotero/storage/L2KHGY7U/Thein et al. - 2018 - An image preprocessing method for kidney stone seg.pdf:application/pdf},
}

@article{yamaev_neural_2021,
	title = {Neural {Network} for {Data} {Preprocessing} in {Computed} {Tomography}},
	volume = {82},
	issn = {0005-1179, 1608-3032},
	url = {https://link.springer.com/10.1134/S000511792110012X},
	doi = {10.1134/S000511792110012X},
	abstract = {We propose a lightweight noise-canceling filtering neural network that implements the filtering stage in the algorithm for tomographic reconstruction of convolution and backprojection (Filtered BackProjection—FBP). We substantiate the neural network architecture, selected on the basis of the possibility of approximating the ramp filtering operation with sufficient accuracy. The network performance has been demonstrated using synthetic data that mimics low-exposure tomographic projections. The quantum nature of X-ray radiation, the exposure time of one frame, and the nonlinear response of the ionizing radiation detector are taken into account when generating the synthetic data. The reconstruction time using the proposed network is 11 times shorter than that of the heavy networks selected for comparison, with the reconstruction quality in the SSIM metric above 0.9.},
	language = {en},
	number = {10},
	urldate = {2024-03-23},
	journal = {Automation and Remote Control},
	author = {Yamaev, A. V. and Chukalina, M. V. and Nikolaev, D. P. and Sheshkus, A. V. and Chulichkov, A. I.},
	month = oct,
	year = {2021},
	pages = {1752--1762},
	file = {Yamaev et al. - 2021 - Neural Network for Data Preprocessing in Computed .pdf:/Users/jasiekjaniszewski/Zotero/storage/DMYFEJ6G/Yamaev et al. - 2021 - Neural Network for Data Preprocessing in Computed .pdf:application/pdf},
}

@incollection{anguera_impact_2018,
	address = {Singapore},
	title = {Impact of {Deep} {Learning} in {Image} {Processing} and {Computer} {Vision}},
	volume = {471},
	isbn = {978-981-10-7328-1 978-981-10-7329-8},
	url = {http://link.springer.com/10.1007/978-981-10-7329-8_48},
	abstract = {With deep learning techniques, a revolution has taken place in the ﬁeld of image processing and computer vision. The survey paper emphasizes the importance of representation learning methods for machine learning tasks. Deep learning, the modern machine learning is commonly used in the vision tasks—semantic segmentation, image captioning, object detection, recognition, and image classiﬁcation. The paper focuses on the recent developments in the domain of remote sensing, retinal image understanding, and scene understanding based on newly proposed deep architectures. The author ﬁnds it quite intriguing of the classical building blocks of image segmentation (Gabor, K-means), shifting gear, and contributing to image recognition tasks based on deep learning (Gabor convolutional network, K-means dictionary learning). The survey makes an attempt to serve as a concise guide in providing latest works in computer vision applications based on deep learning and giving futuristic insights.},
	language = {en},
	urldate = {2024-04-03},
	booktitle = {Microelectronics, {Electromagnetics} and {Telecommunications}},
	publisher = {Springer Singapore},
	author = {Goswami, Tilottama},
	editor = {Anguera, Jaume and Satapathy, Suresh Chandra and Bhateja, Vikrant and Sunitha, K.V.N.},
	year = {2018},
	doi = {10.1007/978-981-10-7329-8_48},
	note = {Series Title: Lecture Notes in Electrical Engineering},
	pages = {475--485},
	file = {Goswami - 2018 - Impact of Deep Learning in Image Processing and Co.pdf:/Users/jasiekjaniszewski/Zotero/storage/JKGR88Y8/Goswami - 2018 - Impact of Deep Learning in Image Processing and Co.pdf:application/pdf},
}

@misc{yao_cnn_2023,
	title = {From {CNN} to {Transformer}: {A} {Review} of {Medical} {Image} {Segmentation} {Models}},
	shorttitle = {From {CNN} to {Transformer}},
	url = {http://arxiv.org/abs/2308.05305},
	abstract = {Medical image segmentation is an important step in medical image analysis, especially as a crucial prerequisite for efficient disease diagnosis and treatment. The use of deep learning for image segmentation has become a prevalent trend. The widely adopted approach currently is U-Net and its variants. Additionally, with the remarkable success of pre-trained models in natural language processing tasks, transformer-based models like TransUNet have achieved desirable performance on multiple medical image segmentation datasets. In this paper, we conduct a survey of the most representative four medical image segmentation models in recent years. We theoretically analyze the characteristics of these models and quantitatively evaluate their performance on two benchmark datasets (i.e., Tuberculosis Chest X-rays and ovarian tumors). Finally, we discuss the main challenges and future trends in medical image segmentation. Our work can assist researchers in the related field to quickly establish medical segmentation models tailored to specific regions.},
	language = {en},
	urldate = {2024-04-05},
	publisher = {arXiv},
	author = {Yao, Wenjian and Bai, Jiajun and Liao, Wei and Chen, Yuheng and Liu, Mengjuan and Xie, Yao},
	month = aug,
	year = {2023},
	note = {arXiv:2308.05305 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Yao et al. - 2023 - From CNN to Transformer A Review of Medical Image.pdf:/Users/jasiekjaniszewski/Zotero/storage/SS4PMGWP/Yao et al. - 2023 - From CNN to Transformer A Review of Medical Image.pdf:application/pdf},
}

@article{bilic_liver_2023,
	title = {The {Liver} {Tumor} {Segmentation} {Benchmark} ({LiTS})},
	volume = {84},
	issn = {13618415},
	url = {http://arxiv.org/abs/1901.04056},
	doi = {10.1016/j.media.2022.102680},
	abstract = {In this work, we report the set-up and results of the Liver Tumor Segmentation Benchmark (LiTS), which was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI) 2017 and the International Conferences on Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2017 and 2018. The image dataset is diverse and contains primary and secondary tumors with varied sizes and appearances with various lesion-to-background levels (hyper-/hypo-dense), created in collaboration with seven hospitals and research institutions. Seventy-five submitted liver and liver tumor segmentation algorithms were trained on a set of 131 computed tomography (CT) volumes and were tested on 70 unseen test images acquired from different patients. We found that not a single algorithm performed best for both liver and liver tumors in the three events. The best liver segmentation algorithm achieved a Dice score of 0.963, whereas, for tumor segmentation, the best algorithms achieved Dices scores of 0.674 (ISBI 2017), 0.702 (MICCAI 2017), and 0.739 (MICCAI 2018). Retrospectively, we performed additional analysis on liver tumor detection and revealed that not all top-performing segmentation algorithms worked well for tumor detection. The best liver tumor detection method achieved a lesion-wise recall of 0.458 (ISBI 2017), 0.515 (MICCAI 2017), and 0.554 (MICCAI 2018), indicating the need for further research. LiTS remains an active benchmark and resource for research, e.g., contributing the liver-related segmentation tasks in {\textbackslash}url\{http://medicaldecathlon.com/\}. In addition, both data and online evaluation are accessible via {\textbackslash}url\{www.lits-challenge.com\}.},
	language = {en},
	urldate = {2024-04-05},
	journal = {Medical Image Analysis},
	author = {Bilic, Patrick and Christ, Patrick and Li, Hongwei Bran and Vorontsov, Eugene and Ben-Cohen, Avi and Kaissis, Georgios and Szeskin, Adi and Jacobs, Colin and Mamani, Gabriel Efrain Humpire and Chartrand, Gabriel and Lohöfer, Fabian and Holch, Julian Walter and Sommer, Wieland and Hofmann, Felix and Hostettler, Alexandre and Lev-Cohain, Naama and Drozdzal, Michal and Amitai, Michal Marianne and Vivantik, Refael and Sosna, Jacob and Ezhov, Ivan and Sekuboyina, Anjany and Navarro, Fernando and Kofler, Florian and Paetzold, Johannes C. and Shit, Suprosanna and Hu, Xiaobin and Lipková, Jana and Rempfler, Markus and Piraud, Marie and Kirschke, Jan and Wiestler, Benedikt and Zhang, Zhiheng and Hülsemeyer, Christian and Beetz, Marcel and Ettlinger, Florian and Antonelli, Michela and Bae, Woong and Bellver, Míriam and Bi, Lei and Chen, Hao and Chlebus, Grzegorz and Dam, Erik B. and Dou, Qi and Fu, Chi-Wing and Georgescu, Bogdan and Giró-i-Nieto, Xavier and Gruen, Felix and Han, Xu and Heng, Pheng-Ann and Hesser, Jürgen and Moltz, Jan Hendrik and Igel, Christian and Isensee, Fabian and Jäger, Paul and Jia, Fucang and Kaluva, Krishna Chaitanya and Khened, Mahendra and Kim, Ildoo and Kim, Jae-Hun and Kim, Sungwoong and Kohl, Simon and Konopczynski, Tomasz and Kori, Avinash and Krishnamurthi, Ganapathy and Li, Fan and Li, Hongchao and Li, Junbo and Li, Xiaomeng and Lowengrub, John and Ma, Jun and Maier-Hein, Klaus and Maninis, Kevis-Kokitsi and Meine, Hans and Merhof, Dorit and Pai, Akshay and Perslev, Mathias and Petersen, Jens and Pont-Tuset, Jordi and Qi, Jin and Qi, Xiaojuan and Rippel, Oliver and Roth, Karsten and Sarasua, Ignacio and Schenk, Andrea and Shen, Zengming and Torres, Jordi and Wachinger, Christian and Wang, Chunliang and Weninger, Leon and Wu, Jianrong and Xu, Daguang and Yang, Xiaoping and Yu, Simon Chun-Ho and Yuan, Yading and Yu, Miao and Zhang, Liping and Cardoso, Jorge and Bakas, Spyridon and Braren, Rickmer and Heinemann, Volker and Pal, Christopher and Tang, An and Kadoury, Samuel and Soler, Luc and van Ginneken, Bram and Greenspan, Hayit and Joskowicz, Leo and Menze, Bjoern},
	month = feb,
	year = {2023},
	note = {arXiv:1901.04056 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {102680},
	file = {Bilic et al. - 2023 - The Liver Tumor Segmentation Benchmark (LiTS).pdf:/Users/jasiekjaniszewski/Zotero/storage/S244TZBH/Bilic et al. - 2023 - The Liver Tumor Segmentation Benchmark (LiTS).pdf:application/pdf},
}

@incollection{navab_u-net_2015,
	address = {Cham},
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	volume = {9351},
	isbn = {978-3-319-24573-7 978-3-319-24574-4},
	shorttitle = {U-{Net}},
	url = {http://link.springer.com/10.1007/978-3-319-24574-4_28},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more eﬃciently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caﬀe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
	language = {en},
	urldate = {2024-04-05},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	year = {2015},
	doi = {10.1007/978-3-319-24574-4_28},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {234--241},
	file = {Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:/Users/jasiekjaniszewski/Zotero/storage/9SBAA89R/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf},
}

@article{gut_benchmarking_2022,
	title = {Benchmarking of {Deep} {Architectures} for {Segmentation} of {Medical} {Images}},
	volume = {41},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {0278-0062, 1558-254X},
	url = {https://ieeexplore.ieee.org/document/9789098/},
	doi = {10.1109/TMI.2022.3180435},
	abstract = {In recent years, there were many suggestions regarding modiﬁcations of the well-known U-Net architecture in order to improve its performance. The central motivation of this work is to provide a fair comparison of U-Net and its ﬁve extensions using identical conditions to disentangle the inﬂuence of model architecture, model training, and parameter settings on the performance of a trained model. For this purpose each of these six segmentation architectures is trained on the same nine data sets. The data sets are selected to cover various imaging modalities (X-rays, computed tomography, magnetic resonance imaging), single- and multi-class segmentation problems, and single- and multi-modal inputs. During the training, it is ensured that the data preprocessing, data set split into training, validation, and testing subsets, optimizer, learning rate change strategy, architecture depth, loss function, supervision and inference are exactly the same for all the architectures compared. Performance is evaluated in terms of Dice coefﬁcient, surface Dice coefﬁcient, average surface distance, Hausdorff distance, training, and prediction time. The main contribution of this experimental study is demonstrating that the architecture variants do not improve the quality of inference related to the basic U-Net architecture while resource demand rises.},
	language = {en},
	number = {11},
	urldate = {2024-04-05},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Gut, Daniel and Tabor, Zbislaw and Szymkowski, Mateusz and Rozynek, Milosz and Kucybala, Iwona and Wojciechowski, Wadim},
	month = nov,
	year = {2022},
	pages = {3231--3241},
	file = {Gut et al. - 2022 - Benchmarking of Deep Architectures for Segmentatio.pdf:/Users/jasiekjaniszewski/Zotero/storage/42E63KRT/Gut et al. - 2022 - Benchmarking of Deep Architectures for Segmentatio.pdf:application/pdf},
}

@article{li_rdctrans_2022,
	title = {{RDCTrans} {U}-{Net}: {A} {Hybrid} {Variable} {Architecture} for {Liver} {CT} {Image} {Segmentation}},
	volume = {22},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	shorttitle = {{RDCTrans} {U}-{Net}},
	url = {https://www.mdpi.com/1424-8220/22/7/2452},
	doi = {10.3390/s22072452},
	abstract = {Segmenting medical images is a necessary prerequisite for disease diagnosis and treatment planning. Among various medical image segmentation tasks, U-Net-based variants have been widely used in liver tumor segmentation tasks. In view of the highly variable shape and size of tumors, in order to improve the accuracy of segmentation, this paper proposes a U-Net-based hybrid variable structure—RDCTrans U-Net for liver tumor segmentation in computed tomography (CT) examinations. We design a backbone network dominated by ResNeXt50 and supplemented by dilated convolution to increase the network depth, expand the perceptual ﬁeld, and improve the efﬁciency of feature extraction without increasing the parameters. At the same time, Transformer is introduced in down-sampling to increase the network’s overall perception and global understanding of the image and to improve the accuracy of liver tumor segmentation. The method proposed in this paper tests the segmentation performance of liver tumors on the LiTS (Liver Tumor Segmentation) dataset. It obtained 89.22\% mIoU and 98.91\% Acc, for liver and tumor segmentation. The proposed model also achieved 93.38\% Dice and 89.87\% Dice, respectively. Compared with the original U-Net and the U-Net model that introduces dense connection, attention mechanism, and Transformer, respectively, the method proposed in this paper achieves SOTA (state of art) results.},
	language = {en},
	number = {7},
	urldate = {2024-04-05},
	journal = {Sensors},
	author = {Li, Lingyun and Ma, Hongbing},
	month = mar,
	year = {2022},
	pages = {2452},
	file = {Li and Ma - 2022 - RDCTrans U-Net A Hybrid Variable Architecture for.pdf:/Users/jasiekjaniszewski/Zotero/storage/J8T4MAG5/Li and Ma - 2022 - RDCTrans U-Net A Hybrid Variable Architecture for.pdf:application/pdf},
}

@article{nisa_dual_2022,
	title = {Dual {U}-{Net} with {Resnet} {Encoder} for {Segmentation} of {Medical} {Images}},
	volume = {13},
	issn = {21565570, 2158107X},
	url = {http://thesai.org/Publications/ViewPaper?Volume=13&Issue=12&Code=IJACSA&SerialNo=65},
	doi = {10.14569/IJACSA.2022.0131265},
	abstract = {Segmentation of medical images has been the most demanding and growing area currently for analysis of medical images. Segmentation of polyp images is a huge challenge because of the variability of color depth and morphology in polyps throughout colonoscopy imaging. For segmentation, in this work, we have used a dataset of images of the gastrointestinal polyp. The algorithms used in this paper for segmentation of gastrointestinal polyp images depend on profound deep convolutional neural network architectures: FCN, Dual U-net with Resnet Encoder, U-net, and Unet\_Resnet. To improve the performance, data augmentation is performed on the dataset. The efficiency of the algorithms is measured by using metrics such as Dice Similarity Coefficient (DSC) and Intersection Over Union (IOU). The algorithm Dual U-net with Resnet Encoder obtains a higher DSC of 0.87 and IOU of 0.80 and beats the other algorithms U-net, FCN, and Unet\_Resnet in segmentation of gastrointestinal polyp images.},
	language = {en},
	number = {12},
	urldate = {2024-04-05},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {Nisa, Syed Qamrun and Ismail, Amelia Ritahani},
	year = {2022},
	file = {Nisa and Ismail - 2022 - Dual U-Net with Resnet Encoder for Segmentation of.pdf:/Users/jasiekjaniszewski/Zotero/storage/VBC9HLSU/Nisa and Ismail - 2022 - Dual U-Net with Resnet Encoder for Segmentation of.pdf:application/pdf},
}

@incollection{liu_image_2017,
	address = {Cham},
	title = {Image {Segmentation} with {Pyramid} {Dilated} {Convolution} {Based} on {ResNet} and {U}-{Net}},
	volume = {10635},
	isbn = {978-3-319-70095-3 978-3-319-70096-0},
	url = {http://link.springer.com/10.1007/978-3-319-70096-0_38},
	abstract = {Various deep convolutional neural networks (CNNs) have been applied in the task of medical image segmentation. A lot of CNNs have been proved to get better performance than the traditional algorithms. Deep residual network (ResNet) has drastically improved the performance by a trainable deep structure. In this paper, we proposed a new end-to-end network based on ResNet and U-Net. Our CNN eﬀectively combine the features from shallow and deep layers through multipath information confusion. In order to exploit global context features and enlarge receptive ﬁeld in deep layer without losing resolution, We designed a new structure called pyramid dilated convolution. Diﬀerent from traditional networks of CNNs, our network replaces the pooling layer with convolutional layer which can reduce information loss to some extent. We also introduce the LeakyReLU instead of ReLU along the downsampling path to increase the expressiveness of our model. Experiment shows that our proposed method can successfully extract features for medical image segmentation.},
	language = {en},
	urldate = {2024-04-05},
	booktitle = {Neural {Information} {Processing}},
	publisher = {Springer International Publishing},
	author = {Zhang, Qiao and Cui, Zhipeng and Niu, Xiaoguang and Geng, Shijie and Qiao, Yu},
	editor = {Liu, Derong and Xie, Shengli and Li, Yuanqing and Zhao, Dongbin and El-Alfy, El-Sayed M.},
	year = {2017},
	doi = {10.1007/978-3-319-70096-0_38},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {364--372},
	file = {Zhang et al. - 2017 - Image Segmentation with Pyramid Dilated Convolutio.pdf:/Users/jasiekjaniszewski/Zotero/storage/W73JBWTG/Zhang et al. - 2017 - Image Segmentation with Pyramid Dilated Convolutio.pdf:application/pdf},
}

@article{cai_review_2020,
	title = {A review of the application of deep learning in medical image classification and segmentation},
	volume = {8},
	issn = {23055839, 23055847},
	url = {http://atm.amegroups.com/article/view/36944/html},
	doi = {10.21037/atm.2020.02.44},
	abstract = {Big medical data mainly include electronic health record data, medical image data, gene information data, etc. Among them, medical image data account for the vast majority of medical data at this stage. How to apply big medical data to clinical practice? This is an issue of great concern to medical and computer researchers, and intelligent imaging and deep learning provide a good answer. This review introduces the application of intelligent imaging and deep learning in the field of big data analysis and early diagnosis of diseases, combining the latest research progress of big data analysis of medical images and the work of our team in the field of big data analysis of medical imagec, especially the classification and segmentation of medical images.},
	language = {en},
	number = {11},
	urldate = {2024-04-05},
	journal = {Annals of Translational Medicine},
	author = {Cai, Lei and Gao, Jingyang and Zhao, Di},
	month = jun,
	year = {2020},
	pages = {713--713},
	file = {Cai et al. - 2020 - A review of the application of deep learning in me.pdf:/Users/jasiekjaniszewski/Zotero/storage/STX85QFU/Cai et al. - 2020 - A review of the application of deep learning in me.pdf:application/pdf},
}

@article{boykov_graph_2006,
	title = {Graph {Cuts} and {Efficient} {N}-{D} {Image} {Segmentation}},
	volume = {70},
	copyright = {http://www.springer.com/tdm},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/s11263-006-7934-5},
	doi = {10.1007/s11263-006-7934-5},
	abstract = {Combinatorial graph cut algorithms have been successfully applied to a wide range of problems in vision and graphics. This paper focusses on possibly the simplest application of graph-cuts: segmentation of objects in image data. Despite its simplicity, this application epitomizes the best features of combinatorial graph cuts methods in vision: global optima, practical efﬁciency, numerical robustness, ability to fuse a wide range of visual cues and constraints, unrestricted topological properties of segments, and applicability to N-D problems. Graph cuts based approaches to object extraction have also been shown to have interesting connections with earlier segmentation methods such as snakes, geodesic active contours, and level-sets. The segmentation energies optimized by graph cuts combine boundary regularization with region-based properties in the same fashion as Mumford-Shah style functionals. We present motivation and detailed technical description of the basic combinatorial optimization framework for image segmentation via s/t graph cuts. After the general concept of using binary graph cut algorithms for object segmentation was ﬁrst proposed and tested in Boykov and Jolly (2001), this idea was widely studied in computer vision and graphics communities. We provide links to a large number of known extensions based on iterative parameter re-estimation and learning, multi-scale or hierarchical approaches, narrow bands, and other techniques for demanding photo, video, and medical applications.},
	language = {en},
	number = {2},
	urldate = {2024-04-13},
	journal = {International Journal of Computer Vision},
	author = {Boykov, Yuri and Funka-Lea, Gareth},
	month = nov,
	year = {2006},
	pages = {109--131},
	file = {Boykov and Funka-Lea - 2006 - Graph Cuts and Efficient N-D Image Segmentation.pdf:/Users/jasiekjaniszewski/Zotero/storage/3B6IUCUA/Boykov and Funka-Lea - 2006 - Graph Cuts and Efficient N-D Image Segmentation.pdf:application/pdf},
}

@article{fan_seeded_2005,
	title = {Seeded region growing: an extensive and comparative study},
	volume = {26},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {01678655},
	shorttitle = {Seeded region growing},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865504003150},
	doi = {10.1016/j.patrec.2004.10.010},
	abstract = {Seeded region growing (SRG) algorithm is very attractive for semantic image segmentation by involving high-level knowledge of image components in the seed selection procedure. However, the SRG algorithm also suﬀers from the problems of pixel sorting orders for labeling and automatic seed selection. An obvious way to improve the SRG algorithm is to provide more eﬀective pixel labeling technique and automate the process of seed selection. To provide such a framework, we design an automatic SRG algorithm, along with a boundary-oriented parallel pixel labeling technique and an automatic seed selection method. Moreover, a seed tracking algorithm is proposed for automatic moving object extraction. The region seeds, which are located inside the temporal change mask, are selected for generating the regions of moving objects. Experimental evaluation shows good performances of our technique on a relatively large variety of images without the need of adjusting parameters.},
	language = {en},
	number = {8},
	urldate = {2024-04-13},
	journal = {Pattern Recognition Letters},
	author = {Fan, Jianping and Zeng, Guihua and Body, Mathurin and Hacid, Mohand-Said},
	month = jun,
	year = {2005},
	pages = {1139--1156},
	file = {Fan et al. - 2005 - Seeded region growing an extensive and comparativ.pdf:/Users/jasiekjaniszewski/Zotero/storage/PSBFIHLI/Fan et al. - 2005 - Seeded region growing an extensive and comparativ.pdf:application/pdf},
}

@article{kass_snakes_1988,
	title = {Snakes: {Active} contour models},
	volume = {1},
	copyright = {http://www.springer.com/tdm},
	issn = {0920-5691, 1573-1405},
	shorttitle = {Snakes},
	url = {http://link.springer.com/10.1007/BF00133570},
	doi = {10.1007/BF00133570},
	abstract = {A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they lock onto nearby edges, localizing them accurately. Scale-space continuation can be used to enlarge the capture region surrounding a feature. Snakes provide a unified account of a number of visual problems, including detection of edges, lines, and subjective contours; motion tracking; and stereo matching. We have used snakes successfully for interactive interpretation, in which user-imposed constraint forces guide the snake near features of interest.},
	language = {en},
	number = {4},
	urldate = {2024-04-13},
	journal = {International Journal of Computer Vision},
	author = {Kass, Michael and Witkin, Andrew and Terzopoulos, Demetri},
	month = jan,
	year = {1988},
	pages = {321--331},
	file = {Kass et al. - 1988 - Snakes Active contour models.pdf:/Users/jasiekjaniszewski/Zotero/storage/4V45WU5A/Kass et al. - 1988 - Snakes Active contour models.pdf:application/pdf},
}

@article{heimann_statistical_2009,
	title = {Statistical shape models for {3D} medical image segmentation: {A} review},
	volume = {13},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {13618415},
	shorttitle = {Statistical shape models for {3D} medical image segmentation},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841509000425},
	doi = {10.1016/j.media.2009.05.004},
	abstract = {Statistical shape models (SSMs) have by now been ﬁrmly established as a robust tool for segmentation of medical images. While 2D models have been in use since the early 1990s, wide-spread utilization of three-dimensional models appeared only in recent years, primarily made possible by breakthroughs in automatic detection of shape correspondences. In this article, we review the techniques required to create and employ these 3D SSMs. While we concentrate on landmark-based shape representations and thoroughly examine the most popular variants of Active Shape and Active Appearance models, we also describe several alternative approaches to statistical shape modeling. Structured into the topics of shape representation, model construction, shape correspondence, local appearance models and search algorithms, we present an overview of the current state of the art in the ﬁeld. We conclude with a survey of applications in the medical ﬁeld and a discussion of future developments.},
	language = {en},
	number = {4},
	urldate = {2024-04-13},
	journal = {Medical Image Analysis},
	author = {Heimann, Tobias and Meinzer, Hans-Peter},
	month = aug,
	year = {2009},
	pages = {543--563},
	file = {Heimann and Meinzer - 2009 - Statistical shape models for 3D medical image segm.pdf:/Users/jasiekjaniszewski/Zotero/storage/6QIX4NKP/Heimann and Meinzer - 2009 - Statistical shape models for 3D medical image segm.pdf:application/pdf},
}

@inproceedings{jie_lu_automatic_2012,
	address = {Hong Kong},
	title = {Automatic liver segmentation in {CT} images based on {Support} {Vector} {Machine}},
	isbn = {978-1-4577-2177-9 978-1-4577-2176-2 978-1-4577-2175-5},
	url = {http://ieeexplore.ieee.org/document/6211581/},
	doi = {10.1109/BHI.2012.6211581},
	abstract = {Accurate and fully automated segmentation of liver parenchyma in medical images is necessary prerequisites for a variety of clinical and research applications, such as constructing three dimension anatomical model. In this paper, an automatic liver segmentation method based on Support Vector Machines (SVM) has been proposed. Segmentation is started by wavelet transform for image feature extraction. Subsequently,SVM is applied on the feature vectors for training and testing to realize pixel classification. Finally, region-growing is used to refine the result ofSVM. Experiments have been conducted on different training-test partitions of the CT image datasets. Compared to manual segmentation provided by medical experts, our experimental results demonstrated the effectiveness of the proposed method.},
	language = {en},
	urldate = {2024-04-13},
	booktitle = {Proceedings of 2012 {IEEE}-{EMBS} {International} {Conference} on {Biomedical} and {Health} {Informatics}},
	publisher = {IEEE},
	author = {{Jie Lu} and {Defeng Wang} and {Lin Shi} and {Pheng Ann Heng}},
	month = jan,
	year = {2012},
	pages = {333--336},
	file = {Jie Lu et al. - 2012 - Automatic liver segmentation in CT images based on.pdf:/Users/jasiekjaniszewski/Zotero/storage/LCP8HR4V/Jie Lu et al. - 2012 - Automatic liver segmentation in CT images based on.pdf:application/pdf},
}

@inproceedings{hadjiiski_3d_2015,
	address = {Orlando, Florida, United States},
	title = {{3D} statistical shape models incorporating {3D} random forest regression voting for robust {CT} liver segmentation},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2082909},
	doi = {10.1117/12.2082909},
	abstract = {During image segmentation, 3D Statistical Shape Models (SSM) usually conduct a limited search for target landmarks within one-dimensional search proﬁles perpendicular to the model surface. In addition, landmark appearance is modeled only locally based on linear proﬁles and weak learners, altogether leading to segmentation errors from landmark ambiguities and limited search coverage. We present a new method for 3D SSM segmentation based on 3D Random Forest Regression Voting. For each surface landmark, a Random Regression Forest is trained that learns a 3D spatial displacement function between the according reference landmark and a set of surrounding sample points, based on an iniﬁnite set of non-local randomized 3D Haar-like features. Landmark search is then conducted omni-directionally within 3D search spaces, where voxelwise forest predictions on landmark position contribute to a common voting map which reﬂects the overall position estimate. Segmentation experiments were conducted on a set of 45 CT volumes of the human liver, of which 40 images were randomly chosen for training and 5 for testing. Without parameter optimization, using a simple candidate selection and a single resolution approach, excellent results were achieved, while faster convergence and better concavity segmentation were observed, altogether underlining the potential of our approach in terms of increased robustness from distinct landmark detection and from better search coverage.},
	language = {en},
	urldate = {2024-04-13},
	author = {Norajitra, Tobias and Meinzer, Hans-Peter and Maier-Hein, Klaus H.},
	editor = {Hadjiiski, Lubomir M. and Tourassi, Georgia D.},
	month = mar,
	year = {2015},
	pages = {941406},
	file = {Norajitra et al. - 2015 - 3D statistical shape models incorporating 3D rando.pdf:/Users/jasiekjaniszewski/Zotero/storage/QZP7439V/Norajitra et al. - 2015 - 3D statistical shape models incorporating 3D rando.pdf:application/pdf},
}

@misc{kirillov_panoptic_2019,
	title = {Panoptic {Segmentation}},
	url = {http://arxiv.org/abs/1801.00868},
	abstract = {We propose and study a task we name panoptic segmentation (PS). Panoptic segmentation uniﬁes the typically distinct tasks of semantic segmentation (assign a class label to each pixel) and instance segmentation (detect and segment each object instance). The proposed task requires generating a coherent scene segmentation that is rich and complete, an important step toward real-world vision systems. While early work in computer vision addressed related image/scene parsing tasks, these are not currently popular, possibly due to lack of appropriate metrics or associated recognition challenges. To address this, we propose a novel panoptic quality (PQ) metric that captures performance for all classes (stuff and things) in an interpretable and uniﬁed manner. Using the proposed metric, we perform a rigorous study of both human and machine performance for PS on three existing datasets, revealing interesting insights about the task. The aim of our work is to revive the interest of the community in a more uniﬁed view of image segmentation.},
	language = {en},
	urldate = {2024-04-14},
	publisher = {arXiv},
	author = {Kirillov, Alexander and He, Kaiming and Girshick, Ross and Rother, Carsten and Dollár, Piotr},
	month = apr,
	year = {2019},
	note = {arXiv:1801.00868 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Kirillov et al. - 2019 - Panoptic Segmentation.pdf:/Users/jasiekjaniszewski/Zotero/storage/6RYFL3MZ/Kirillov et al. - 2019 - Panoptic Segmentation.pdf:application/pdf},
}

@article{gotra_liver_2017,
	title = {Liver segmentation: indications, techniques and future directions},
	volume = {8},
	issn = {1869-4101},
	shorttitle = {Liver segmentation},
	url = {http://link.springer.com/10.1007/s13244-017-0558-1},
	doi = {10.1007/s13244-017-0558-1},
	abstract = {Methods Using images from CT and MRI, this paper reviews the indications for liver segmentation, technical approaches used in segmentation software and the developing roles of liver segmentation in clinical practice.
Results Liver segmentation for volumetric assessment is indicated prior to major hepatectomy, portal vein embolisation, associating liver partition and portal vein ligation for staged hepatectomy (ALPPS) and transplant. Segmentation software can be categorised according to amount of user input involved: manual, semi-automated and fully automated. Manual segmentation is considered the Bgold standard{\textasciicircum} in clinical practice and research, but is tedious and time-consuming. Increasingly automated segmentation approaches are more robust, but may suffer from certain segmentation pitfalls. Emerging applications of segmentation include surgical planning and integration with MRI-based biomarkers.
Conclusions Liver segmentation has multiple clinical applications and is expanding in scope. Clinicians can employ semi-automated or fully automated segmentation options to more efficiently integrate volumetry into clinical practice.},
	language = {en},
	number = {4},
	urldate = {2024-04-15},
	journal = {Insights into Imaging},
	author = {Gotra, Akshat and Sivakumaran, Lojan and Chartrand, Gabriel and Vu, Kim-Nhien and Vandenbroucke-Menu, Franck and Kauffmann, Claude and Kadoury, Samuel and Gallix, Benoît and De Guise, Jacques A. and Tang, An},
	month = aug,
	year = {2017},
	pages = {377--392},
	file = {Gotra et al. - 2017 - Liver segmentation indications, techniques and fu.pdf:/Users/jasiekjaniszewski/Zotero/storage/WBHGTP8J/Gotra et al. - 2017 - Liver segmentation indications, techniques and fu.pdf:application/pdf},
}

@article{hirsch_radiologist-level_2022,
	title = {Radiologist-{Level} {Performance} by {Using} {Deep} {Learning} for {Segmentation} of {Breast} {Cancers} on {MRI} {Scans}},
	volume = {4},
	issn = {2638-6100},
	url = {http://pubs.rsna.org/doi/10.1148/ryai.200231},
	doi = {10.1148/ryai.200231},
	abstract = {Purpose:  To develop a deep network architecture that would achieve fully automated radiologist-level segmentation of cancers at breast MRI. Materials and Methods:  In this retrospective study, 38 229 examinations (composed of 64 063 individual breast scans from 14 475 patients) were performed in female patients (age range, 12–94 years; mean age, 52 years 6 10 [standard deviation]) who presented between 2002 and 2014 at a single clinical site. A total of 2555 breast cancers were selected that had been segmented on two-dimensional (2D) images by radiologists, as well as 60 108 benign breasts that served as examples of noncancerous tissue; all these were used for model training. For testing, an additional 250 breast cancers were segmented independently on 2D images by four radiologists. Authors selected among several three-dimensional (3D) deep convolutional neural network architectures, input modalities, and harmonization methods. The outcome measure was the Dice score for 2D segmentation, which was compared between the network and radiologists by using the Wilcoxon signed rank test and the two one-sided test procedure.
Results:  The highest-performing network on the training set was a 3D U-Net with dynamic contrast-enhanced MRI as input and with intensity normalized for each examination. In the test set, the median Dice score of this network was 0.77 (interquartile range, 0.26). The performance of the network was equivalent to that of the radiologists (two one-sided test procedures with radiologist performance of 0.69–0.84 as equivalence bounds, P , .001 for both; n = 250).
Conclusion:  When trained on a sufficiently large dataset, the developed 3D U-Net performed as well as fellowship-trained radiologists in detailed 2D segmentation of breast cancers at routine clinical MRI.},
	language = {en},
	number = {1},
	urldate = {2024-04-15},
	journal = {Radiology: Artificial Intelligence},
	author = {Hirsch, Lukas and Huang, Yu and Luo, Shaojun and Rossi Saccarelli, Carolina and Lo Gullo, Roberto and Daimiel Naranjo, Isaac and Bitencourt, Almir G. V. and Onishi, Natsuko and Ko, Eun Sook and Leithner, Doris and Avendano, Daly and Eskreis-Winkler, Sarah and Hughes, Mary and Martinez, Danny F. and Pinker, Katja and Juluru, Krishna and El-Rowmeim, Amin E. and Elnajjar, Pierre and Morris, Elizabeth A. and Makse, Hernan A. and Parra, Lucas C. and Sutton, Elizabeth J.},
	month = jan,
	year = {2022},
	pages = {e200231},
	file = {Hirsch et al. - 2022 - Radiologist-Level Performance by Using Deep Learni.pdf:/Users/jasiekjaniszewski/Zotero/storage/39ZBW6G6/Hirsch et al. - 2022 - Radiologist-Level Performance by Using Deep Learni.pdf:application/pdf},
}

@article{liu_review_2021,
	title = {A {Review} of {Deep}-{Learning}-{Based} {Medical} {Image} {Segmentation} {Methods}},
	volume = {13},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2071-1050},
	url = {https://www.mdpi.com/2071-1050/13/3/1224},
	doi = {10.3390/su13031224},
	abstract = {As an emerging biomedical image processing technology, medical image segmentation has made great contributions to sustainable medical care. Now it has become an important research direction in the ﬁeld of computer vision. With the rapid development of deep learning, medical image processing based on deep convolutional neural networks has become a research hotspot. This paper focuses on the research of medical image segmentation based on deep learning. First, the basic ideas and characteristics of medical image segmentation based on deep learning are introduced. By explaining its research status and summarizing the three main methods of medical image segmentation and their own limitations, the future development direction is expanded. Based on the discussion of different pathological tissues and organs, the speciﬁcity between them and their classic segmentation algorithms are summarized. Despite the great achievements of medical image segmentation in recent years, medical image segmentation based on deep learning has still encountered difﬁculties in research. For example, the segmentation accuracy is not high, the number of medical images in the data set is small and the resolution is low. The inaccurate segmentation results are unable to meet the actual clinical requirements. Aiming at the above problems, a comprehensive review of current medical image segmentation methods based on deep learning is provided to help researchers solve existing problems.},
	language = {en},
	number = {3},
	urldate = {2024-04-15},
	journal = {Sustainability},
	author = {Liu, Xiangbin and Song, Liping and Liu, Shuai and Zhang, Yudong},
	month = jan,
	year = {2021},
	pages = {1224},
	file = {Liu et al. - 2021 - A Review of Deep-Learning-Based Medical Image Segm.pdf:/Users/jasiekjaniszewski/Zotero/storage/LLDSKT95/Liu et al. - 2021 - A Review of Deep-Learning-Based Medical Image Segm.pdf:application/pdf},
}

@article{li_automatic_2015,
	title = {Automatic {Segmentation} of {Liver} {Tumor} in {CT} {Images} with {Deep} {Convolutional} {Neural} {Networks}},
	volume = {03},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {2327-5219, 2327-5227},
	url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/jcc.2015.311023},
	doi = {10.4236/jcc.2015.311023},
	abstract = {Liver tumors segmentation from computed tomography (CT) images is an essential task for diagnosis and treatments of liver cancer. However, it is difficult owing to the variability of appearances, fuzzy boundaries, heterogeneous densities, shapes and sizes of lesions. In this paper, an automatic method based on convolutional neural networks (CNNs) is presented to segment lesions from CT images. The CNNs is one of deep learning models with some convolutional filters which can learn hierarchical features from data. We compared the CNNs model to popular machine learning algorithms: AdaBoost, Random Forests (RF), and support vector machine (SVM). These classifiers were trained by handcrafted features containing mean, variance, and contextual features. Experimental evaluation was performed on 30 portal phase enhanced CT images using leave-one-out cross validation. The average Dice Similarity Coefficient (DSC), precision, and recall achieved of 80.06\% ± 1.63\%, 82.67\% ± 1.43\%, and 84.34\% ± 1.61\%, respectively. The results show that the CNNs method has better performance than other methods and is promising in liver tumor segmentation.},
	language = {en},
	number = {11},
	urldate = {2024-04-15},
	journal = {Journal of Computer and Communications},
	author = {Li, Wen and Jia, Fucang and Hu, Qingmao},
	year = {2015},
	pages = {146--151},
	file = {Li et al. - 2015 - Automatic Segmentation of Liver Tumor in CT Images.pdf:/Users/jasiekjaniszewski/Zotero/storage/2QHIEXKW/Li et al. - 2015 - Automatic Segmentation of Liver Tumor in CT Images.pdf:application/pdf},
}

@misc{oshea_introduction_2015,
	title = {An {Introduction} to {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1511.08458},
	abstract = {The ﬁeld of machine learning has taken a dramatic twist in recent times, with the rise of the Artiﬁcial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artiﬁcial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difﬁcult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simpliﬁed method of getting started with ANNs.},
	language = {en},
	urldate = {2024-04-15},
	publisher = {arXiv},
	author = {O'Shea, Keiron and Nash, Ryan},
	month = dec,
	year = {2015},
	note = {arXiv:1511.08458 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {O'Shea and Nash - 2015 - An Introduction to Convolutional Neural Networks.pdf:/Users/jasiekjaniszewski/Zotero/storage/QJ6369HD/O'Shea and Nash - 2015 - An Introduction to Convolutional Neural Networks.pdf:application/pdf},
}

@article{seo_modified_2020,
	title = {Modified {U}-{Net} ({mU}-{Net}) {With} {Incorporation} of {Object}-{Dependent} {High} {Level} {Features} for {Improved} {Liver} and {Liver}-{Tumor} {Segmentation} in {CT} {Images}},
	volume = {39},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0278-0062, 1558-254X},
	url = {https://ieeexplore.ieee.org/document/8876857/},
	doi = {10.1109/TMI.2019.2948320},
	language = {en},
	number = {5},
	urldate = {2024-04-16},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Seo, Hyunseok and Huang, Charles and Bassenne, Maxime and Xiao, Ruoxiu and Xing, Lei},
	month = may,
	year = {2020},
	pages = {1316--1325},
	file = {Seo et al. - 2020 - Modified U-Net (mU-Net) With Incorporation of Obje.pdf:/Users/jasiekjaniszewski/Zotero/storage/XZR7J9AU/Seo et al. - 2020 - Modified U-Net (mU-Net) With Incorporation of Obje.pdf:application/pdf},
}

@article{bilic_liver_2023-1,
	title = {The {Liver} {Tumor} {Segmentation} {Benchmark} ({LiTS})},
	volume = {84},
	issn = {13618415},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841522003085},
	doi = {10.1016/j.media.2022.102680},
	language = {en},
	urldate = {2024-04-16},
	journal = {Medical Image Analysis},
	author = {Bilic, Patrick and Christ, Patrick and Li, Hongwei Bran and Vorontsov, Eugene and Ben-Cohen, Avi and Kaissis, Georgios and Szeskin, Adi and Jacobs, Colin and Mamani, Gabriel Efrain Humpire and Chartrand, Gabriel and Lohöfer, Fabian and Holch, Julian Walter and Sommer, Wieland and Hofmann, Felix and Hostettler, Alexandre and Lev-Cohain, Naama and Drozdzal, Michal and Amitai, Michal Marianne and Vivanti, Refael and Sosna, Jacob and Ezhov, Ivan and Sekuboyina, Anjany and Navarro, Fernando and Kofler, Florian and Paetzold, Johannes C. and Shit, Suprosanna and Hu, Xiaobin and Lipková, Jana and Rempfler, Markus and Piraud, Marie and Kirschke, Jan and Wiestler, Benedikt and Zhang, Zhiheng and Hülsemeyer, Christian and Beetz, Marcel and Ettlinger, Florian and Antonelli, Michela and Bae, Woong and Bellver, Míriam and Bi, Lei and Chen, Hao and Chlebus, Grzegorz and Dam, Erik B. and Dou, Qi and Fu, Chi-Wing and Georgescu, Bogdan and Giró-i-Nieto, Xavier and Gruen, Felix and Han, Xu and Heng, Pheng-Ann and Hesser, Jürgen and Moltz, Jan Hendrik and Igel, Christian and Isensee, Fabian and Jäger, Paul and Jia, Fucang and Kaluva, Krishna Chaitanya and Khened, Mahendra and Kim, Ildoo and Kim, Jae-Hun and Kim, Sungwoong and Kohl, Simon and Konopczynski, Tomasz and Kori, Avinash and Krishnamurthi, Ganapathy and Li, Fan and Li, Hongchao and Li, Junbo and Li, Xiaomeng and Lowengrub, John and Ma, Jun and Maier-Hein, Klaus and Maninis, Kevis-Kokitsi and Meine, Hans and Merhof, Dorit and Pai, Akshay and Perslev, Mathias and Petersen, Jens and Pont-Tuset, Jordi and Qi, Jin and Qi, Xiaojuan and Rippel, Oliver and Roth, Karsten and Sarasua, Ignacio and Schenk, Andrea and Shen, Zengming and Torres, Jordi and Wachinger, Christian and Wang, Chunliang and Weninger, Leon and Wu, Jianrong and Xu, Daguang and Yang, Xiaoping and Yu, Simon Chun-Ho and Yuan, Yading and Yue, Miao and Zhang, Liping and Cardoso, Jorge and Bakas, Spyridon and Braren, Rickmer and Heinemann, Volker and Pal, Christopher and Tang, An and Kadoury, Samuel and Soler, Luc and Van Ginneken, Bram and Greenspan, Hayit and Joskowicz, Leo and Menze, Bjoern},
	month = feb,
	year = {2023},
	pages = {102680},
	file = {Bilic et al. - 2023 - The Liver Tumor Segmentation Benchmark (LiTS).pdf:/Users/jasiekjaniszewski/Zotero/storage/SUJJQIEG/Bilic et al. - 2023 - The Liver Tumor Segmentation Benchmark (LiTS).pdf:application/pdf},
}

@article{long_fully_nodate,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixelsto-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efﬁcient inference and learning. We deﬁne and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classiﬁcation networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by ﬁne-tuning [3] to the segmentation task. We then deﬁne a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, ﬁne layer to produce accurate and detailed segmentations. Our fully convolutional network achieves stateof-the-art segmentation of PASCAL VOC (20\% relative improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one ﬁfth of a second for a typical image.},
	language = {en},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	file = {Long et al. - Fully Convolutional Networks for Semantic Segmenta.pdf:/Users/jasiekjaniszewski/Zotero/storage/FM6TY6U7/Long et al. - Fully Convolutional Networks for Semantic Segmenta.pdf:application/pdf},
}

@incollection{carneiro_fully_2016,
	address = {Cham},
	title = {Fully {Convolutional} {Network} for {Liver} {Segmentation} and {Lesions} {Detection}},
	volume = {10008},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-319-46975-1 978-3-319-46976-8},
	url = {http://link.springer.com/10.1007/978-3-319-46976-8_9},
	abstract = {In this work we explore a fully convolutional network (FCN) for the task of liver segmentation and liver metastases detection in computed tomography (CT) examinations. FCN has proven to be a very powerful tool for semantic segmentation. We explore the FCN performance on a relatively small dataset and compare it to patch based CNN and sparsity based classiﬁcation schemes. Our data contains CT examinations from 20 patients with overall 68 lesions and 43 livers marked in one slice and 20 diﬀerent patients with a full 3D liver segmentation. We ran 3-fold cross-validation and results indicate superiority of the FCN over all other methods tested. Using our fully automatic algorithm we achieved true positive rate of 0.86 and 0.6 false positive per case which are very promising and clinically relevant results.},
	language = {en},
	urldate = {2024-04-16},
	booktitle = {Deep {Learning} and {Data} {Labeling} for {Medical} {Applications}},
	publisher = {Springer International Publishing},
	author = {Ben-Cohen, Avi and Diamant, Idit and Klang, Eyal and Amitai, Michal and Greenspan, Hayit},
	editor = {Carneiro, Gustavo and Mateus, Diana and Peter, Loïc and Bradley, Andrew and Tavares, João Manuel R. S. and Belagiannis, Vasileios and Papa, João Paulo and Nascimento, Jacinto C. and Loog, Marco and Lu, Zhi and Cardoso, Jaime S. and Cornebise, Julien},
	year = {2016},
	doi = {10.1007/978-3-319-46976-8_9},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {77--85},
	file = {Ben-Cohen et al. - 2016 - Fully Convolutional Network for Liver Segmentation.pdf:/Users/jasiekjaniszewski/Zotero/storage/Q4EZPHML/Ben-Cohen et al. - 2016 - Fully Convolutional Network for Liver Segmentation.pdf:application/pdf},
}

@misc{christ_automatic_2017,
	title = {Automatic {Liver} and {Tumor} {Segmentation} of {CT} and {MRI} {Volumes} using {Cascaded} {Fully} {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1702.05970},
	abstract = {Automatic segmentation of the liver and hepatic lesions is an important step towards deriving quantitative biomarkers for accurate clinical diagnosis and computer-aided decision support systems. This paper presents a method to automatically segment liver and lesions in CT and MRI abdomen images using cascaded fully convolutional neural networks (CFCNs) enabling the segmentation of large-scale medical trials and quantitative image analyses. We train and cascade two FCNs for the combined segmentation of the liver and its lesions. As a ﬁrst step, we train an FCN to segment the liver as ROI input for a second FCN. The second FCN solely segments lesions within the predicted liver ROIs of step 1. CFCN models were trained on an abdominal CT dataset comprising 100 hepatic tumor volumes. Validation results on further datasets show that CFCN-based semantic liver and lesion segmentation achieves Dice scores over 94\% for the liver with computation times below 100s per volume. We further experimentally demonstrate the robustness of the proposed method on 38 MRI liver tumor volumes and the public 3DIRCAD dataset.},
	language = {en},
	urldate = {2024-04-16},
	publisher = {arXiv},
	author = {Christ, Patrick Ferdinand and Ettlinger, Florian and Grün, Felix and Elshaera, Mohamed Ezzeldin A. and Lipkova, Jana and Schlecht, Sebastian and Ahmaddy, Freba and Tatavarty, Sunil and Bickel, Marc and Bilic, Patrick and Rempfler, Markus and Hofmann, Felix and Anastasi, Melvin D. and Ahmadi, Seyed-Ahmad and Kaissis, Georgios and Holch, Julian and Sommer, Wieland and Braren, Rickmer and Heinemann, Volker and Menze, Bjoern},
	month = feb,
	year = {2017},
	note = {arXiv:1702.05970 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {Christ et al. - 2017 - Automatic Liver and Tumor Segmentation of CT and M.pdf:/Users/jasiekjaniszewski/Zotero/storage/F799HZWD/Christ et al. - 2017 - Automatic Liver and Tumor Segmentation of CT and M.pdf:application/pdf},
}

@article{zoetmulder_domain-_2022,
	title = {Domain- and task-specific transfer learning for medical segmentation tasks},
	volume = {214},
	issn = {01692607},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169260721006131},
	doi = {10.1016/j.cmpb.2021.106539},
	language = {en},
	urldate = {2024-04-16},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Zoetmulder, Riaan and Gavves, Efstratios and Caan, Matthan and Marquering, Henk},
	month = feb,
	year = {2022},
	pages = {106539},
	file = {Zoetmulder et al. - 2022 - Domain- and task-specific transfer learning for me.pdf:/Users/jasiekjaniszewski/Zotero/storage/BUVTD8WG/Zoetmulder et al. - 2022 - Domain- and task-specific transfer learning for me.pdf:application/pdf},
}

@article{kavur_chaos_2021,
	title = {{CHAOS} {Challenge} - combined ({CT}-{MR}) healthy abdominal organ segmentation},
	volume = {69},
	issn = {13618415},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841520303145},
	doi = {10.1016/j.media.2020.101950},
	language = {en},
	urldate = {2024-04-17},
	journal = {Medical Image Analysis},
	author = {Kavur, A. Emre and Gezer, N. Sinem and Barış, Mustafa and Aslan, Sinem and Conze, Pierre-Henri and Groza, Vladimir and Pham, Duc Duy and Chatterjee, Soumick and Ernst, Philipp and Özkan, Savaş and Baydar, Bora and Lachinov, Dmitry and Han, Shuo and Pauli, Josef and Isensee, Fabian and Perkonigg, Matthias and Sathish, Rachana and Rajan, Ronnie and Sheet, Debdoot and Dovletov, Gurbandurdy and Speck, Oliver and Nürnberger, Andreas and Maier-Hein, Klaus H. and Bozdağı Akar, Gözde and Ünal, Gözde and Dicle, Oğuz and Selver, M. Alper},
	month = apr,
	year = {2021},
	pages = {101950},
	file = {Kavur et al. - 2021 - CHAOS Challenge - combined (CT-MR) healthy abdomin.pdf:/Users/jasiekjaniszewski/Zotero/storage/87ZAUBPH/Kavur et al. - 2021 - CHAOS Challenge - combined (CT-MR) healthy abdomin.pdf:application/pdf},
}

@article{xu_liver_2020,
	title = {Liver segmentation based on region growing and level set active contour model with new signed pressure force function},
	volume = {202},
	issn = {00304026},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0030402619316031},
	doi = {10.1016/j.ijleo.2019.163705},
	language = {en},
	urldate = {2024-04-18},
	journal = {Optik},
	author = {Xu, Lei and Zhu, Yingliang and Zhang, Yuhao and Yang, Haima},
	month = feb,
	year = {2020},
	pages = {163705},
	file = {Xu et al. - 2020 - Liver segmentation based on region growing and lev.pdf:/Users/jasiekjaniszewski/Zotero/storage/FDM5GNMD/Xu et al. - 2020 - Liver segmentation based on region growing and lev.pdf:application/pdf},
}

@article{kim_paip_2021,
	title = {{PAIP} 2019: {Liver} cancer segmentation challenge},
	volume = {67},
	issn = {13618415},
	shorttitle = {{PAIP} 2019},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841520302188},
	doi = {10.1016/j.media.2020.101854},
	language = {en},
	urldate = {2024-04-24},
	journal = {Medical Image Analysis},
	author = {Kim, Yoo Jung and Jang, Hyungjoon and Lee, Kyoungbun and Park, Seongkeun and Min, Sung-Gyu and Hong, Choyeon and Park, Jeong Hwan and Lee, Kanggeun and Kim, Jisoo and Hong, Wonjae and Jung, Hyun and Liu, Yanling and Rajkumar, Haran and Khened, Mahendra and Krishnamurthi, Ganapathy and Yang, Sen and Wang, Xiyue and Han, Chang Hee and Kwak, Jin Tae and Ma, Jianqiang and Tang, Zhe and Marami, Bahram and Zeineh, Jack and Zhao, Zixu and Heng, Pheng-Ann and Schmitz, Rüdiger and Madesta, Frederic and Rösch, Thomas and Werner, Rene and Tian, Jie and Puybareau, Elodie and Bovio, Matteo and Zhang, Xiufeng and Zhu, Yifeng and Chun, Se Young and Jeong, Won-Ki and Park, Peom and Choi, Jinwook},
	month = jan,
	year = {2021},
	pages = {101854},
	file = {Kim et al. - 2021 - PAIP 2019 Liver cancer segmentation challenge.pdf:/Users/jasiekjaniszewski/Zotero/storage/6F4CD2TL/Kim et al. - 2021 - PAIP 2019 Liver cancer segmentation challenge.pdf:application/pdf},
}

@inproceedings{islam_evaluation_2021,
	address = {Islamabad, Pakistan},
	title = {Evaluation of {Preprocessing} {Techniques} for {U}-{Net} {Based} {Automated} {Liver} {Segmentation}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-66543-293-1},
	url = {https://ieeexplore.ieee.org/document/9445204/},
	doi = {10.1109/ICAI52203.2021.9445204},
	abstract = {To extract liver from medical images is achallenging task due to similar intensity values of liver with adjacent organs, various contrast levels, various noise associated with medical images and irregular shape of liver. To address these issues, it is important to preprocess the medical images, i.e., computerized tomography (CT) and magnetic resonance imaging (MRI) data prior to liver analysis and quantification. This paper investigates the impact of permutation of various preprocessing techniques for CT images, on the automated liver segmentation using deep learning, i.e., U-Net architecture. The study focuses on Hounsfield Unit (HU) windowing, contrast limited adaptive histogram equalization (CLAHE), z-score normalization, median filtering and Block-Matching and 3D (BM3D) filtering. The segmented results show that combination of three techniques; HU-windowing, median filtering and z-score normalization achieve optimal performance with Dice coefficient of 96.93\%, 90.77\% and 90.84\% for training, validation and testing respectively.},
	language = {en},
	urldate = {2024-04-25},
	booktitle = {2021 {International} {Conference} on {Artificial} {Intelligence} ({ICAI})},
	publisher = {IEEE},
	author = {Islam, Muhammad and Khan, Kaleem Nawaz and Khan, Muhammad Salman},
	month = apr,
	year = {2021},
	pages = {187--192},
	file = {Islam et al. - 2021 - Evaluation of Preprocessing Techniques for U-Net B.pdf:/Users/jasiekjaniszewski/Zotero/storage/SZKXWIW9/Islam et al. - 2021 - Evaluation of Preprocessing Techniques for U-Net B.pdf:application/pdf},
}

@article{whalen_slice_2003,
	title = {The {Slice} {Is} {Right} ({An} {Exercise} in {CT} {Windowing})},
	volume = {34},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {08205930},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0820593009600335},
	doi = {10.1016/S0820-5930(09)60033-5},
	abstract = {This article was adapted from a poster display presentation and is offered in the form of a workbook exercise. Its object is to teach students and other novices the fine art of CT windowing. When asked how window widths and levels work, I invariably use the analogy of the Range Finder Game from the game show The Price is Right for demonstration purposes. I employ the comparison from the popular game show to demonstrate what window widths and window levels are, and how they work in unison. This exercise employs two minor differences from the TV game. Number one, the monetary scale has been replaced by a CT number scale. Number two, the movable range finder that has a fixed scale on the game show, is replaced by a range finder (WW) scale, which can alter its range.},
	language = {en},
	number = {4},
	urldate = {2024-04-26},
	journal = {Canadian Journal of Medical Radiation Technology},
	author = {Whalen, Bruce},
	month = dec,
	year = {2003},
	pages = {5--10},
	file = {Whalen - 2003 - The Slice Is Right (An Exercise in CT Windowing).pdf:/Users/jasiekjaniszewski/Zotero/storage/GHZ2K6QP/Whalen - 2003 - The Slice Is Right (An Exercise in CT Windowing).pdf:application/pdf},
}

@article{garg_comparative_2017,
	title = {A {Comparative} {Study} on {Histogram}               {Equalization} and {Cumulative} {Histogram} {Equalization}},
	volume = {3},
	abstract = {Image enhancement is a way to improve the appearance of image to human viewers or to image processing system performance. Image Enhancement techniques can be classified into two categories as spatial domain and frequency domain. There are five image enhancement algorithms in spatial domain using FPGA technology. These algorithms are: median filter, contrast stretching, histogram equalization, negative image transformation and power-law transformation. This review paper presents different methods of histogram equalization. Histogram equalization is a method to enhance an image very efficiently. Histogram equalization methods are Histogram expansion, Local area histogram equalization (LAHE), Cumulative histogram equalization, Par sectioning, odd sectioning.},
	language = {en},
	number = {9},
	author = {Garg, Priyanka},
	year = {2017},
	file = {Garg - 2017 - A Comparative Study on Histogram               Equ.pdf:/Users/jasiekjaniszewski/Zotero/storage/QXJEAETU/Garg - 2017 - A Comparative Study on Histogram               Equ.pdf:application/pdf},
}

@article{fan_brief_2019,
	title = {Brief review of image denoising techniques},
	volume = {2},
	issn = {2524-4442},
	url = {https://vciba.springeropen.com/articles/10.1186/s42492-019-0016-7},
	doi = {10.1186/s42492-019-0016-7},
	abstract = {With the explosion in the number of digital images taken every day, the demand for more accurate and visually pleasing images is increasing. However, the images captured by modern cameras are inevitably degraded by noise, which leads to deteriorated visual image quality. Therefore, work is required to reduce noise without losing image features (edges, corners, and other sharp structures). So far, researchers have already proposed various methods for decreasing noise. Each method has its own advantages and disadvantages. In this paper, we summarize some important research in the field of image denoising. First, we give the formulation of the image denoising problem, and then we present several image denoising techniques. In addition, we discuss the characteristics of these techniques. Finally, we provide several promising directions for future research.},
	language = {en},
	number = {1},
	urldate = {2024-04-26},
	journal = {Visual Computing for Industry, Biomedicine, and Art},
	author = {Fan, Linwei and Zhang, Fan and Fan, Hui and Zhang, Caiming},
	month = dec,
	year = {2019},
	pages = {7},
	file = {Fan et al. - 2019 - Brief review of image denoising techniques.pdf:/Users/jasiekjaniszewski/Zotero/storage/WSDQH82U/Fan et al. - 2019 - Brief review of image denoising techniques.pdf:application/pdf},
}

@article{survarachakan_deep_2022,
	title = {Deep learning for image-based liver analysis — {A} comprehensive review focusing on malignant lesions},
	volume = {130},
	issn = {09333657},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0933365722000963},
	doi = {10.1016/j.artmed.2022.102331},
	abstract = {Deep learning-based methods, in particular, convolutional neural networks and fully convolutional networks are now widely used in the medical image analysis domain. The scope of this review focuses on the analysis using deep learning of focal liver lesions, with a special interest in hepatocellular carcinoma and metastatic cancer; and structures like the parenchyma or the vascular system. Here, we address several neural network architectures used for analyzing the anatomical structures and lesions in the liver from various imaging modalities such as computed tomography, magnetic resonance imaging and ultrasound. Image analysis tasks like segmentation, object detection and classification for the liver, liver vessels and liver lesions are discussed. Based on the qualitative search, 91 papers were filtered out for the survey, including journal publications and conference proceedings. The papers reviewed in this work are grouped into eight categories based on the methodologies used. By comparing the evaluation metrics, hybrid models performed better for both the liver and the lesion segmentation tasks, ensemble classifiers performed better for the vessel segmentation tasks and combined approach performed better for both the lesion classification and detection tasks. The performance was measured based on the Dice score for the segmentation, and accuracy for the classification and detection tasks, which are the most commonly used metrics.},
	language = {en},
	urldate = {2024-04-26},
	journal = {Artificial Intelligence in Medicine},
	author = {Survarachakan, Shanmugapriya and Prasad, Pravda Jith Ray and Naseem, Rabia and Pérez De Frutos, Javier and Kumar, Rahul Prasanna and Langø, Thomas and Alaya Cheikh, Faouzi and Elle, Ole Jakob and Lindseth, Frank},
	month = aug,
	year = {2022},
	pages = {102331},
	file = {Survarachakan et al. - 2022 - Deep learning for image-based liver analysis — A c.pdf:/Users/jasiekjaniszewski/Zotero/storage/4VN9FGT9/Survarachakan et al. - 2022 - Deep learning for image-based liver analysis — A c.pdf:application/pdf},
}

@article{gul_deep_2022,
	title = {Deep learning techniques for liver and liver tumor segmentation: {A} review},
	volume = {147},
	issn = {00104825},
	shorttitle = {Deep learning techniques for liver and liver tumor segmentation},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010482522004127},
	doi = {10.1016/j.compbiomed.2022.105620},
	abstract = {Liver and liver tumor segmentation from 3D volumetric images has been an active research area in the medical image processing domain for the last few decades. The existence of other organs such as the heart, spleen, stomach, and kidneys complicate liver segmentation and tumor identification task since these organs share identical properties in terms of shape, texture, and intensity values. Many automatic and semi-automatic tech­ niques have been presented in recent years, in an attempt to establish a system for the reliable diagnosis and detection of liver illnesses, specifically liver tumors. With the evolution of deep learning techniques and their exceptional performance in the field of medical image processing, medical image segmentation in volumetric images using deep learning techniques has received a great deal of emphasis. The goal of this study is to provide an overview of the available deep learning approaches for segmenting liver and detecting liver tumors, as well as their evaluation metrics including accuracy, volume overlap error, dice coefficient, and mean square distance. This research also includes a detailed overview of the various 3D volumetric imaging architectures, designed specifically for the task of semantic segmentation. The comparison of approaches offered in earlier challenges for liver and tumor segmentation, as well as their dice scores derived from respective site sources, is also provided.},
	language = {en},
	urldate = {2024-04-26},
	journal = {Computers in Biology and Medicine},
	author = {Gul, Sidra and Khan, Muhammad Salman and Bibi, Asima and Khandakar, Amith and Ayari, Mohamed Arselene and Chowdhury, Muhammad E.H.},
	month = aug,
	year = {2022},
	pages = {105620},
	file = {Gul et al. - 2022 - Deep learning techniques for liver and liver tumor.pdf:/Users/jasiekjaniszewski/Zotero/storage/Y7MKXPY7/Gul et al. - 2022 - Deep learning techniques for liver and liver tumor.pdf:application/pdf},
}

@article{valente_automatic_2016,
	title = {Automatic {3D} pulmonary nodule detection in {CT} images: {A} survey},
	volume = {124},
	issn = {01692607},
	shorttitle = {Automatic {3D} pulmonary nodule detection in {CT} images},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169260715300298},
	doi = {10.1016/j.cmpb.2015.10.006},
	language = {en},
	urldate = {2024-04-26},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Valente, Igor Rafael S. and Cortez, Paulo César and Neto, Edson Cavalcanti and Soares, José Marques and De Albuquerque, Victor Hugo C. and Tavares, João Manuel R.S.},
	month = feb,
	year = {2016},
	pages = {91--107},
	file = {Valente et al. - 2016 - Automatic 3D pulmonary nodule detection in CT imag.pdf:/Users/jasiekjaniszewski/Zotero/storage/7HNWX487/Valente et al. - 2016 - Automatic 3D pulmonary nodule detection in CT imag.pdf:application/pdf},
}

@inproceedings{truong_medical_2018,
	address = {Penang, Malaysia},
	title = {Medical {Images} {Sequence} {Normalization} and {Augmentation}: {Improve} {Liver} {Tumor} {Segmentation} from {Small} {Dataset}},
	isbn = {978-1-5386-7738-4},
	shorttitle = {Medical {Images} {Sequence} {Normalization} and {Augmentation}},
	url = {https://ieeexplore.ieee.org/document/8780008/},
	doi = {10.1109/CRC.2018.00010},
	abstract = {Using deep learning for Medical Images Diagnosis automatically is a new trend in recent years. Concretely, the fundamental step in these studies is the automatic segmentation system for human organ, that has the benefit of accuracy in the diagnosis process for medical images (CT images). Traditionally, if there is no module of automatic segmentation system, this process has to be performed by the experience of specialized physicians. More importantly, this process takes much time of physicians, while the automatic segmentation system can alternative efficiently. However, the accuracy and responsiveness are the challenges for a segmentation system with a small organ or small tissue, i.e., a liver tumor, because of the lack of data for deep learning.},
	language = {en},
	urldate = {2024-04-29},
	booktitle = {2018 3rd {International} {Conference} on {Control}, {Robotics} and {Cybernetics} ({CRC})},
	publisher = {IEEE},
	author = {Truong, Thanh-Nghia and Dam, Vu-Duy and Le, Thanh-Sach},
	month = sep,
	year = {2018},
	pages = {1--5},
	file = {Truong et al. - 2018 - Medical Images Sequence Normalization and Augmenta.pdf:/Users/jasiekjaniszewski/Zotero/storage/VYKBCICI/Truong et al. - 2018 - Medical Images Sequence Normalization and Augmenta.pdf:application/pdf},
}

@inproceedings{chen_wavelet-based_2013,
	address = {Beijing, China},
	title = {Wavelet-based denoising: {A} brief review},
	isbn = {978-1-4673-6249-8 978-1-4673-6248-1 978-1-4673-6247-4},
	shorttitle = {Wavelet-based denoising},
	url = {http://ieeexplore.ieee.org/document/6568140/},
	doi = {10.1109/ICICIP.2013.6568140},
	abstract = {The denoising of Gaussian additive white noise is a classical problem in signal and image processing. In this paper, we classify the most important wavelet denoising methods into different categories and give a brief overview of each method classified. In general, the recently developed block matching and 3D filtering (BM3D) algorithm performs much better than other existing methods published in the literature. We recommend using this method for image denoising because it is currently one of the state-of-the-art denoising methods. The non-local means method and the optimal spatial adaptation (OSA) method are also very successful methods in image denoising.},
	language = {en},
	urldate = {2024-04-29},
	booktitle = {2013 {Fourth} {International} {Conference} on {Intelligent} {Control} and {Information} {Processing} ({ICICIP})},
	publisher = {IEEE},
	author = {Chen, Guangyi and Xie, Wenfang and Zhao, Yongjia},
	month = jun,
	year = {2013},
	pages = {570--574},
	file = {Chen et al. - 2013 - Wavelet-based denoising A brief review.pdf:/Users/jasiekjaniszewski/Zotero/storage/RLBPGDCI/Chen et al. - 2013 - Wavelet-based denoising A brief review.pdf:application/pdf},
}

@article{diwakar_review_2018,
	title = {A review on {CT} image noise and its denoising},
	volume = {42},
	issn = {17468094},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1746809418300107},
	doi = {10.1016/j.bspc.2018.01.010},
	language = {en},
	urldate = {2024-04-29},
	journal = {Biomedical Signal Processing and Control},
	author = {Diwakar, Manoj and Kumar, Manoj},
	month = apr,
	year = {2018},
	pages = {73--88},
	file = {Diwakar and Kumar - 2018 - A review on CT image noise and its denoising.pdf:/Users/jasiekjaniszewski/Zotero/storage/Z3M9MAJT/Diwakar and Kumar - 2018 - A review on CT image noise and its denoising.pdf:application/pdf},
}

@article{reis_pointwise_nodate,
	title = {Pointwise adaptive estimation for robust and quantile regression},
	abstract = {A nonparametric procedure for robust regression estimation and for quantile regression is proposed which is completely data-driven and adapts locally to the regularity of the regression function. This is achieved by considering in each point M-estimators over diﬀerent local neighbourhoods and by a local model selection procedure based on sequential testing. Nonasymptotic risk bounds are obtained, which yield rate-optimality for large sample asymptotics under weak conditions. Simulations for diﬀerent univariate median regression models show good ﬁnite sample properties, also in comparison to traditional methods. The approach is extended to image denoising and applied to CT scans in cancer research.},
	language = {en},
	author = {Reiß, Markus and Rozenholc, Yves and Cuenod, Charles A},
	file = {Reiß et al. - Pointwise adaptive estimation for robust and quant.pdf:/Users/jasiekjaniszewski/Zotero/storage/AIUHPK8R/Reiß et al. - Pointwise adaptive estimation for robust and quant.pdf:application/pdf},
}

@article{rahman_deep_2022,
	title = {A {Deep} {Learning} {Approach} for {Liver} and {Tumor} {Segmentation} in {CT} {Images} {Using} {ResUNet}},
	volume = {9},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2306-5354},
	url = {https://www.mdpi.com/2306-5354/9/8/368},
	doi = {10.3390/bioengineering9080368},
	abstract = {According to the most recent estimates from global cancer statistics for 2020, liver cancer is the ninth most common cancer in women. Segmenting the liver is difﬁcult, and segmenting the tumor from the liver adds some difﬁculty. After a sample of liver tissue is taken, imaging tests, such as magnetic resonance imaging (MRI), computer tomography (CT), and ultrasound (US), are used to segment the liver and liver tumor. Due to overlapping intensity and variability in the position and shape of soft tissues, segmentation of the liver and tumor from computed abdominal tomography images based on shade gray or shapes is undesirable. This study proposed a more efﬁcient method for segmenting liver and tumors from CT image volumes using a hybrid ResUNet model, combining the ResNet and UNet models to address this gap. The two overlapping models were primarily used in this study to segment the liver and for region of interest (ROI) assessment. Segmentation of the liver is done to examine the liver with an abdominal CT image volume. The proposed model is based on CT volume slices of patients with liver tumors and evaluated on the public 3D dataset IRCADB01. Based on the experimental analysis, the true value accuracy for liver segmentation was found to be approximately 99.55\%, 97.85\%, and 98.16\%. The authentication rate of the dice coefﬁcient also increased, indicating that the experiment went well and that the model is ready to use for the detection of liver tumors.},
	language = {en},
	number = {8},
	urldate = {2024-04-29},
	journal = {Bioengineering},
	author = {Rahman, Hameedur and Bukht, Tanvir Fatima Naik and Imran, Azhar and Tariq, Junaid and Tu, Shanshan and Alzahrani, Abdulkareeem},
	month = aug,
	year = {2022},
	pages = {368},
	file = {Rahman et al. - 2022 - A Deep Learning Approach for Liver and Tumor Segme.pdf:/Users/jasiekjaniszewski/Zotero/storage/5KJA3TG9/Rahman et al. - 2022 - A Deep Learning Approach for Liver and Tumor Segme.pdf:application/pdf},
}

@article{kushnure_ms-unet_2021,
	title = {{MS}-{UNet}: {A} multi-scale {UNet} with feature recalibration approach for automatic liver and tumor segmentation in {CT} images},
	volume = {89},
	issn = {08956111},
	shorttitle = {{MS}-{UNet}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0895611121000331},
	doi = {10.1016/j.compmedimag.2021.101885},
	abstract = {Automatic liver and tumor segmentation play a significant role in clinical interpretation and treatment planning of hepatic diseases. To segment liver and tumor manually from the hundreds of computed tomography (CT) images is tedious and labor-intensive; thus, segmentation becomes expert dependent. In this paper, we proposed the multi-scale approach to improve the receptive field of Convolutional Neural Network (CNN) by representing multi-scale features that extract global and local features at a more granular level. We also recalibrate channelwise responses of the aggregated multi-scale features that enhance the high-level feature description ability of the network. The experimental results demonstrated the efficacy of a proposed model on a publicly available 3Dircadb dataset. The proposed approach achieved a dice similarity score of 97.13 \% for liver and 84.15 \% for tumor. The statistical significance analysis by a statistical test with a p-value demonstrated that the proposed model is statistically significant for a significance level of 0.05 (p-value {\textless} 0.05). The multi-scale approach im­ proves the segmentation performance of the network and reduces the computational complexity and network parameters. The experimental results show that the performance of the proposed method outperforms compared with state-of-the-art methods.},
	language = {en},
	urldate = {2024-04-30},
	journal = {Computerized Medical Imaging and Graphics},
	author = {Kushnure, Devidas T. and Talbar, Sanjay N.},
	month = apr,
	year = {2021},
	pages = {101885},
	file = {Kushnure and Talbar - 2021 - MS-UNet A multi-scale UNet with feature recalibra.pdf:/Users/jasiekjaniszewski/Zotero/storage/H8HTY7GP/Kushnure and Talbar - 2021 - MS-UNet A multi-scale UNet with feature recalibra.pdf:application/pdf},
}

@article{almotairi_liver_2020,
	title = {Liver {Tumor} {Segmentation} in {CT} {Scans} {Using} {Modified} {SegNet}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/5/1516},
	doi = {10.3390/s20051516},
	abstract = {The main cause of death related to cancer worldwide is from hepatic cancer. Detection of hepatic cancer early using computed tomography (CT) could prevent millions of patients’ death every year. However, reading hundreds or even tens of those CT scans is an enormous burden for radiologists. Therefore, there is an immediate need is to read, detect, and evaluate CT scans automatically, quickly, and accurately. However, liver segmentation and extraction from the CT scans is a bottleneck for any system, and is still a challenging problem. In this work, a deep learning-based technique that was proposed for semantic pixel-wise classification of road scenes is adopted and modified to fit liver CT segmentation and classification. The architecture of the deep convolutional encoder–decoder is named SegNet, and consists of a hierarchical correspondence of encode–decoder layers. The proposed architecture was tested on a standard dataset for liver CT scans and achieved tumor accuracy of up to 99.9\% in the training phase.},
	number = {5},
	journal = {Sensors},
	author = {Almotairi, Sultan and Kareem, Ghada and Aouf, Mohamed and Almutairi, Badr and Salem, Mohammed A.-M.},
	year = {2020},
}

@article{meng_liver_2020,
	title = {Liver tumor segmentation based on {3D} convolutional neural network with dual scale},
	volume = {21},
	issn = {1526-9914, 1526-9914},
	url = {https://aapm.onlinelibrary.wiley.com/doi/10.1002/acm2.12784},
	doi = {10.1002/acm2.12784},
	abstract = {Purpose: Liver is one of the organs with a high incidence of tumors in the human body. Malignant liver tumors seriously threaten human life and health. The difﬁculties of liver tumor segmentation from computed tomography (CT) image are: (a) The contrast between the liver tumors and healthy tissues in CT images is low and the boundary is blurred; (b) The image of liver tumor is complex and diversiﬁed in size, shape, and location.
Methods: To solve the above problems, this paper focused on the human liver and liver tumor segmentation algorithm based on convolutional neural network (CNN), and specially designed a three‐dimensional dual path multiscale convolutional neural network (TDP‐CNN). To balance the performance of segmentation and requirement of computational resources, the dual path was used in the network, then the feature maps from both paths were fused at the end of the paths. To reﬁne the segmentation results, we used conditional random ﬁelds (CRF) to eliminate the false segmentation points in the segmentation results to improve the accuracy.
Results: In the experiment, we used the public dataset liver tumor segmentation (LiTS) to analyze the segmentation results qualitatively and quantitatively. Ground truth segmentation of liver and liver tumor was manually labeled by an experienced radiologist. Quantitative metrics were Dice, Hausdorff distance, and average distance. For the segmentation results of liver tumor, Dice was 0.689, Hausdorff distance was 7.69, and the average distance was 1.07; for the segmentation results of the liver, Dice was 0.965, Hausdorff distance was 29.162, and the average distance was 0.197. Compared with other liver and liver tumor segmentation algorithms in Medical Image Computing and Intervention (MICCAI) 2017 competition, our method of liver segmentation ranked ﬁrst, and liver tumor segmentation ranked second.
Conclusions: The experimental results showed that the proposed algorithm had good performance in both liver and liver tumor segmentation.},
	language = {en},
	number = {1},
	urldate = {2024-05-03},
	journal = {Journal of Applied Clinical Medical Physics},
	author = {Meng, Lu and Tian, Yaoyu and Bu, Sihang},
	month = jan,
	year = {2020},
	pages = {144--157},
	file = {Meng et al. - 2020 - Liver tumor segmentation based on 3D convolutional.pdf:/Users/jasiekjaniszewski/Zotero/storage/AZWPZRH6/Meng et al. - 2020 - Liver tumor segmentation based on 3D convolutional.pdf:application/pdf},
}

@inproceedings{zhang_light-weight_2019,
	address = {Macao, China},
	title = {Light-{Weight} {Hybrid} {Convolutional} {Network} for {Liver} {Tumor} {Segmentation}},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/593},
	doi = {10.24963/ijcai.2019/593},
	abstract = {Automated segmentation of liver tumors in contrast-enhanced abdominal computed tomography (CT) scans is essential in assisting medical professionals to evaluate tumor development and make fast therapeutic schedule. Although deep convolutional neural networks (DCNNs) have contributed many breakthroughs in image segmentation, this task remains challenging, since 2D DCNNs are incapable of exploring the inter-slice information and 3D DCNNs are too complex to be trained with the available small dataset. In this paper, we propose the light-weight hybrid convolutional network (LW-HCN) to segment the liver and its tumors in CT volumes. Instead of combining a 2D and a 3D networks for coarse-to-ﬁne segmentation, LW-HCN has a encoder-decoder structure, in which 2D convolutions used at the bottom of the encoder decreases the complexity and 3D convolutions used in other layers explore both spatial and temporal information. To further reduce the complexity, we design the depthwise and spatiotemporal separate (DSTS) factorization for 3D convolutions, which not only reduces parameters dramatically but also improves the performance. We evaluated the proposed LW-HCN model against several recent methods on the LiTS and 3D-IRCADb datasets and achieved, respectively, the Dice per case of 73.0\% and 94.1\% for tumor segmentation, setting a new state of the art.},
	language = {en},
	urldate = {2024-05-03},
	booktitle = {Proceedings of the {Twenty}-{Eighth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Zhang, Jianpeng and Xie, Yutong and Zhang, Pingping and Chen, Hao and Xia, Yong and Shen, Chunhua},
	month = aug,
	year = {2019},
	pages = {4271--4277},
	file = {Zhang et al. - 2019 - Light-Weight Hybrid Convolutional Network for Live.pdf:/Users/jasiekjaniszewski/Zotero/storage/5EQ6U6L6/Zhang et al. - 2019 - Light-Weight Hybrid Convolutional Network for Live.pdf:application/pdf},
}

@misc{smith_cyclical_2017,
	title = {Cyclical {Learning} {Rates} for {Training} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1506.01186},
	abstract = {It is known that the learning rate is the most important hyper-parameter to tune for training deep neural networks. This paper describes a new method for setting the learning rate, named cyclical learning rates, which practically eliminates the need to experimentally ﬁnd the best values and schedule for the global learning rates. Instead of monotonically decreasing the learning rate, this method lets the learning rate cyclically vary between reasonable boundary values. Training with cyclical learning rates instead of ﬁxed values achieves improved classiﬁcation accuracy without a need to tune and often in fewer iterations. This paper also describes a simple way to estimate “reasonable bounds” – linearly increasing the learning rate of the network for a few epochs. In addition, cyclical learning rates are demonstrated on the CIFAR-10 and CIFAR-100 datasets with ResNets, Stochastic Depth networks, and DenseNets, and the ImageNet dataset with the AlexNet and GoogLeNet architectures. These are practical tools for everyone who trains neural networks.},
	language = {en},
	urldate = {2024-05-28},
	publisher = {arXiv},
	author = {Smith, Leslie N.},
	month = apr,
	year = {2017},
	note = {arXiv:1506.01186 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {Smith - 2017 - Cyclical Learning Rates for Training Neural Networ.pdf:/Users/jasiekjaniszewski/Zotero/storage/Z4QR2FWQ/Smith - 2017 - Cyclical Learning Rates for Training Neural Networ.pdf:application/pdf},
}

@misc{howard2018fastai,
  title={fastai},
  author={Howard, Jeremy and others},
  year={2018},
  publisher={GitHub},
  howpublished={\url{https://github.com/fastai/fastai}},
}
@book{python,
 author = {Van Rossum, Guido and Drake, Fred L.},
 title = {Python 3 Reference Manual},
 year = {2009},
 isbn = {1441412697},
 publisher = {CreateSpace},
 address = {Scotts Valley, CA}
}
@incollection{NEURIPS2019_9015,
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  pages     = {8024--8035},
  year      = {2019},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@software{brett_2024_10714563,
  author       = {Brett, Matthew and
                  Markiewicz, Christopher J. and
                  Hanke, Michael and
                  Côté, Marc-Alexandre and
                  Cipollini, Ben and
                  McCarthy, Paul and
                  Jarecka, Dorota and
                  Cheng, Christopher P. and
                  Larson, Eric and
                  Halchenko, Yaroslav O. and
                  Cottaar, Michiel and
                  Ghosh, Satrajit and
                  Wassermann, Demian and
                  Gerhard, Stephan and
                  Lee, Gregory R. and
                  Baratz, Zvi and
                  Wang, Hao-Ting and
                  Papadopoulos Orfanos, Dimitri and
                  Kastman, Erik and
                  Kaczmarzyk, Jakub and
                  Guidotti, Roberto and
                  Daniel, Jonathan and
                  Duek, Or and
                  Rokem, Ariel and
                  Mathieu Scheltienne and
                  Madison, Cindee and
                  Sólon, Anibal and
                  Moloney, Brendan and
                  Morency, Félix C. and
                  Goncalves, Mathias and
                  Markello, Ross and
                  Riddell, Cameron and
                  Burns, Christopher and
                  Millman, Jarrod and
                  Gramfort, Alexandre and
                  Leppäkangas, Jaakko and
                  van den Bosch, Jasper J.F. and
                  Vincent, Robert D. and
                  Braun, Henry and
                  Subramaniam, Krish and
                  Van, Andrew and
                  Gorgolewski, Krzysztof J. and
                  Raamana, Pradeep Reddy and
                  Klug, Julian and
                  Vos de Wael, Reinder and
                  Nichols, B. Nolan and
                  Baker, Eric M. and
                  Hayashi, Soichi and
                  Pinsard, Basile and
                  Haselgrove, Christian and
                  Hymers, Mark and
                  Esteban, Oscar and
                  Koudoro, Serge and
                  Pérez-García, Fernando and
                  Dockès, Jérôme and
                  Oosterhof, Nikolaas N. and
                  Amirbekian, Bago and
                  Christian, Horea and
                  Nimmo-Smith, Ian and
                  Nguyen, Ly and
                  Suter, Peter and
                  Reddigari, Samir and
                  St-Jean, Samuel and
                  Panfilov, Egor and
                  Garyfallidis, Eleftherios and
                  Varoquaux, Gael and
                  Legarreta, Jon Haitz and
                  Hahn, Kevin S. and
                  Waller, Lea and
                  Hinds, Oliver P. and
                  Fauber, Bennet and
                  Dewey, Blake and
                  Perez, Fabian and
                  Roberts, Jacob and
                  Poline, Jean-Baptiste and
                  Stutters, Jon and
                  Jordan, Kesshi and
                  Cieslak, Matthew and
                  Moreno, Miguel Estevan and
                  Hrnčiar, Tomáš and
                  Haenel, Valentin and
                  Schwartz, Yannick and
                  Darwin, Benjamin C and
                  Thirion, Bertrand and
                  Gauthier, Carl and
                  Solovey, Igor and
                  Gonzalez, Ivan and
                  Palasubramaniam, Jath and
                  Lecher, Justin and
                  Leinweber, Katrin and
                  Raktivan, Konstantinos and
                  Calábková, Markéta and
                  Fischer, Peter and
                  Gervais, Philippe and
                  Gadde, Syam and
                  Ballinger, Thomas and
                  Roos, Thomas and
                  Reddam, Venkateswara Reddy and
                  freec84},
  title        = {nipy/nibabel: 5.2.1},
  month        = feb,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {5.2.1},
  doi          = {10.5281/zenodo.10714563},
  url          = {https://doi.org/10.5281/zenodo.10714563}
}

@software{reback2020pandas,
    author       = {The pandas development team},
    title        = {pandas-dev/pandas: Pandas},
    month        = feb,
    year         = 2020,
    publisher    = {Zenodo},
    version      = {latest},
    doi          = {10.5281/zenodo.3509134},
    url          = {https://doi.org/10.5281/zenodo.3509134}
}

@Article{         harris2020array,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}